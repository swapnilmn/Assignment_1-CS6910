{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN2tSBovtOKxJf6BPhV4Sz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnilmn/Assignment_1-CS6910/blob/master/Question_2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\n",
        "\n",
        "Your code should be flexible such that it is easy to change the number of hidden layers and the number of neurons in each hidden layer."
      ],
      "metadata": {
        "id": "v0Q5opYMgYb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries "
      ],
      "metadata": {
        "id": "_dP0oEKrgmQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CZcFz8GygBp5"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist, mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm_notebook "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotEncoder_from_scratch:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.categories = None\n",
        "    def fit(self, X):\n",
        "        self.categories =[]\n",
        "        for i in range(X.shape[1]):\n",
        "            feature_categories =list(set(X[:, i]))\n",
        "            self.categories.append(feature_categories)\n",
        "            \n",
        "    def transform(self, X):\n",
        "        one_hot_vector = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            one_hot_row = []\n",
        "            for j in range(X.shape[1]):\n",
        "\n",
        "                category_index = self.categories[j].index(X[i, j])\n",
        "                category_one_hot =[0] *len(self.categories[j])\n",
        "                category_one_hot[category_index] = 1\n",
        "\n",
        "                one_hot_row.extend(category_one_hot)\n",
        "            one_hot_vector.append(one_hot_row)\n",
        "        return np.array(one_hot_vector)\n",
        "\n",
        "X = np.array([[1],[2]]) \n",
        "enc = OneHotEncoder_from_scratch()\n",
        "enc.fit(X)\n",
        "enc.transform(X)\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "enc.fit(train_labels.reshape(-1, 1))\n",
        "enc.transform(train_labels.reshape(-1, 1))\n",
        "#train_labels.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "sjPsVG8wafVH",
        "outputId": "8b1f6aa2-246f-42c8-dbff-3c8eba45c25f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 1],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'fashion_mnist'\n",
        "if dataset == 'fashion_mnist':\n",
        "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "elif dataset == 'mnist':\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "else:\n",
        "    raise ValueError('Invalid dataset name')\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels, test_size=0.1, random_state=42)\n",
        "train_input = []\n",
        "for i in range(len(X_train)):\n",
        "    train_input.append(list(np.concatenate(X_train[i]).flat))\n",
        "\n",
        "val_input = []\n",
        "for i in range(len(X_val)):\n",
        "    val_input.append(list(np.concatenate(X_val[i]).flat))\n",
        "\n",
        "test_input = []\n",
        "for i in range(len(test_images)):\n",
        "    test_input.append(list(np.concatenate(test_images[i]).flat))\n",
        "Y_train = np.array(Y_train)\n",
        "Y_val = np.array(Y_val)\n",
        "Y_test = np.array(test_labels)\n",
        "\n",
        "X_train = np.array(train_input) / 255.0\n",
        "X_test = np.array(test_input) / 255.0\n",
        "X_val = np.array(val_input) / 255.0\n",
        "\n",
        "enc = OneHotEncoder_from_scratch()\n",
        "enc.fit(Y_train.reshape(-1, 1))\n",
        "Y_train = enc.transform(Y_train.reshape(-1, 1))\n",
        "Y_val = enc.transform(Y_val.reshape(-1, 1))\n",
        "Y_test = enc.transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrLcGXP5QTUp",
        "outputId": "242257ea-d666-44c9-bbde-92e507f5367f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54000, 10) (6000, 10) (10000, 10)\n",
            "(54000, 784) (6000, 784) (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will set a configuartion dictionary for future use for wandb seerp\n",
        "# we will take input from that configuration dict\n",
        "\n",
        "config = {'hidden_layers_size' : [32, 64, 128], # We can modify numbers of neurons each layers, parallaly it will modify number of layers\n",
        "          'pre_activation_function': 'sigmoid',\n",
        "          'weight_initialization_method': 'xavier',\n",
        "          }\n",
        "# Now we will dynamically add no of hidden layers key \n",
        "config['hidden_layers_no'] = len(config['hidden_layers_size'])\n"
      ],
      "metadata": {
        "id": "58U2Q5O1FS1p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FFNetwork:\n",
        "  def __init__(self, X, Y,\n",
        "               epochs = 100, \n",
        "               hidden_layer_count = 4,\n",
        "               hidden_layers =  [32, 64, 128, 256],\n",
        "               learning_rate = 0.001,\n",
        "               batch_size = 32,\n",
        "               activation='tanh',\n",
        "               weight_init='random',\n",
        "               loss = 'MSE',\n",
        "               weight_decay = 0):\n",
        "    \n",
        "    self.inputs =X.shape[1] # Number of inputs\n",
        "    self.outputs= Y.shape[1] # Number of outputs\n",
        "    self.epochs = epochs\n",
        "    self.hidden_layers = hidden_layer_count  # Number of hidden layers \n",
        "    self.network_size= [self.inputs] + hidden_layers +[self.outputs] # input layer + hidden layers + output layers\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.weights={} # It will create dictionary for weights and biases\n",
        "    self.weights_h = []\n",
        "    self.num_classes = Y.shape[1]\n",
        "    self.weight_init = weight_init\n",
        "    self.activation_function = activation\n",
        "    self.loss_function = loss\n",
        "    self.lambd = 0\n",
        "    np.random.seed(0)  # We will set seed value so that it will generate same random numebers every time\n",
        "\n",
        "    self.grad_derivatice={}\n",
        "    self.update_weights={}\n",
        "    self.prev_update_weights={}\n",
        "    for i in range(1,self.hidden_layers+1):\n",
        "      self.update_weights['vw'+str(i)]=0\n",
        "      self.update_weights['vb'+str(i)]=0\n",
        "      self.update_weights['mb'+str(i)]=0\n",
        "      self.update_weights['mw'+str(i)]=0\n",
        "      self.prev_update_weights['vw'+str(i)]=0\n",
        "      self.prev_update_weights['vb'+str(i)]=0\n",
        "    \n",
        "    if self.weight_init == 'random':\n",
        "      for i in range(1,self.hidden_layers+2):\n",
        "        self.weights['W'+str(i)] = np.random.randn(self.network_size[i-1],self.network_size[i])*0.1\n",
        "        self.weights['B'+str(i)] =np.zeros((1,self.network_size[i]))\n",
        "    \n",
        "    elif self.weight_init == 'Xavier':\n",
        "      for i in range(1,self.hidden_layers+2):\n",
        "        self.weights['W'+str(i)]=np.random.randn(self.network_size[i-1],self.network_size[i])*np.sqrt(1/self.network_size[i-1])\n",
        "        self.weights['B'+str(i)] = np.zeros((1,self.network_size[i]))\n",
        "\n",
        "  \n",
        "  def forward_activation(self, X): \n",
        "    if self.activation_function =='sigmoid':\n",
        "      return 1.0/(1.0 +np.exp(-X))\n",
        "    elif self.activation_function== 'tanh':\n",
        "      return  np.tanh(X)\n",
        "    elif self.activation_function =='Relu':\n",
        "      return  np.maximum(0,X)\n",
        "\n",
        "\n",
        "  def grad_activation(self, X):\n",
        "    if self.activation_function =='sigmoid':\n",
        "      return X*(1-X) \n",
        "    elif self.activation_function== 'tanh':\n",
        "      return (1-np.square(X))\n",
        "    elif  self.activation_function == 'Relu':\n",
        "      return 1.0*(X>0)\n",
        "\n",
        "  def softmax(self, X):\n",
        "    exps =np.exp(X -np.max(X, axis=1,keepdims=True))\n",
        "    return  exps/np.sum(exps,axis=1, keepdims=True)\n",
        "  \n",
        "  def forward_pass(self,X, weights=None):\n",
        "    if weights is None:\n",
        "        weights =self.weights\n",
        "    self.z = {}\n",
        "    self.h ={}\n",
        "    self.h[0] =X\n",
        "    for i in range(self.hidden_layers):\n",
        "        self.z[i+1]=np.matmul(self.h[i], weights[f'W{i+1}']) + weights[f'B{i+1}']\n",
        "        self.h[i+1] =self.forward_activation(self.z[i+1])\n",
        "    self.z[self.hidden_layers+1] = np.matmul(self.h[self.hidden_layers],weights[f'W{self.hidden_layers+1}']) +weights[f'B{self.hidden_layers+1}']\n",
        "    self.h[self.hidden_layers+1] =self.softmax(self.z[self.hidden_layers+1])\n",
        "    return self.h[self.hidden_layers+1]   \n",
        "  \n",
        "model = FFNetwork(X_train, Y_train,\n",
        "                  epochs = 1, \n",
        "                  hidden_layer_count = 4,\n",
        "                  hidden_layers =  [32, 64, 128, 256],\n",
        "                  learning_rate = 0.001,\n",
        "                  batch_size = 32,\n",
        "                  activation='Relu',\n",
        "                  weight_init='random',\n",
        "                  loss = 'CE')\n",
        "model.forward_pass(X_train)[0]"
      ],
      "metadata": {
        "id": "fjDM3VLYdkxY",
        "outputId": "f0b69834-54b5-4301-cb9e-625a30d19f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10439453, 0.10853244, 0.09621989, 0.09402379, 0.09662353,\n",
              "       0.10174432, 0.09815351, 0.10075173, 0.10590278, 0.09365347])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}