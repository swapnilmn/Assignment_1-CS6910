{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnilmn/Assignment_1-CS6910/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dP0oEKrgmQc"
      },
      "source": [
        "# Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZcFz8GygBp5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "from keras.datasets import fashion_mnist, mnist\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm_notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn2b1ZpMPZ6d",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiqBs52vjT6P"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "import numpy as np\n",
        "class OneHotEncoder_:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.categories = None\n",
        "        \n",
        "    def fit(self, X):\n",
        "        self.categories = []\n",
        "        for i in range(X.shape[1]):\n",
        "            feature_categories = list(set(X[:, i]))\n",
        "            self.categories.append(feature_categories)\n",
        "            \n",
        "    def transform(self, X):\n",
        "        one_hot_matrix = []\n",
        "        for i in range(X.shape[0]):\n",
        "            one_hot_row = []\n",
        "            for j in range(X.shape[1]):\n",
        "                category_index = self.categories[j].index(X[i, j])\n",
        "                category_one_hot = [0] * len(self.categories[j])\n",
        "                category_one_hot[category_index] = 1\n",
        "                one_hot_row.extend(category_one_hot)\n",
        "            one_hot_matrix.append(one_hot_row)\n",
        "        return np.array(one_hot_matrix)\n",
        "X = np.array([[1],[2]]) \n",
        "enc = OneHotEncoder_()\n",
        "print(enc.fit(X))\n",
        "enc.transform(X)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ktgxyqIvwoE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QffBdZdZ9h2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "dataset = 'fashion_mnist'\n",
        "if dataset == 'fashion_mnist':\n",
        "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "elif dataset == 'mnist':\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "else:\n",
        "    raise ValueError('Invalid dataset name')\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "train_input = []\n",
        "for i in range(len(X_train)):\n",
        "    train_input.append(list(np.concatenate(X_train[i]).flat))\n",
        "\n",
        "val_input = []\n",
        "for i in range(len(X_val)):\n",
        "    val_input.append(list(np.concatenate(X_val[i]).flat))\n",
        "\n",
        "test_input = []\n",
        "for i in range(len(test_images)):\n",
        "    test_input.append(list(np.concatenate(test_images[i]).flat))\n",
        "\n",
        "Y_train = np.array(Y_train)\n",
        "Y_val = np.array(Y_val)\n",
        "Y_test = np.array(test_labels)\n",
        "\n",
        "X_train = np.array(train_input) / 255.0\n",
        "X_test = np.array(test_input) / 255.0\n",
        "X_val = np.array(val_input) / 255.0\n",
        "\n",
        "enc = OneHotEncoder_()\n",
        "enc.fit(Y_train.reshape(-1, 1))\n",
        "Y_train = enc.transform(Y_train.reshape(-1, 1))\n",
        "Y_val = enc.transform(Y_val.reshape(-1, 1))\n",
        "Y_test = enc.transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j80rnJZjjYxh"
      },
      "source": [
        "# FFNW Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgYIbPp6SLL5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "wandb.init(project = 'Question_5')\n",
        "\n",
        "class FFNetwork:\n",
        "  def __init__(self, X, Y,\n",
        "               epochs = 100, \n",
        "               hidden_layer_count = 4,\n",
        "               hidden_layers =  [32, 64, 128, 256],\n",
        "               learning_rate = 0.001,\n",
        "               batch_size = 32,\n",
        "               activation='tanh',\n",
        "               weight_init='random',\n",
        "               loss = 'MSE',\n",
        "               weight_decay = 0):\n",
        "    \n",
        "    self.inputs =X.shape[1] # Number of inputs\n",
        "    self.outputs= Y.shape[1] # Number of outputs\n",
        "    self.epochs = epochs\n",
        "    self.hidden_layers = hidden_layer_count  # Number of hidden layers \n",
        "    self.network_size= [self.inputs] + hidden_layers +[self.outputs] # input layer + hidden layers + output layers\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.weights={} # It will create dictionary for weights and biases\n",
        "    self.weights_h = []\n",
        "    self.num_classes = Y.shape[1]\n",
        "    self.weight_init = weight_init\n",
        "    self.activation_function = activation\n",
        "    self.loss_function = loss\n",
        "    self.lambd = 0\n",
        "    np.random.seed(0)  # We will set seed value so that it will generate same random numebers every time\n",
        "\n",
        "    self.grad_derivatice={}\n",
        "    self.update_weights={}\n",
        "    self.prev_update_weights={}\n",
        "    for i in range(1,self.hidden_layers+1):\n",
        "      vw_key, vb_key, mb_key, mw_key = [f\"{key}{i}\" for key in ['vw', 'vb', 'mb', 'mw']]\n",
        "      self.update_weights[vw_key]=0\n",
        "      self.update_weights[vb_key]=0\n",
        "      self.update_weights[mb_key]=0\n",
        "      self.update_weights[mw_key]=0\n",
        "      self.prev_update_weights[vw_key]=0\n",
        "      self.prev_update_weights[vb_key]=0\n",
        "\n",
        "    \n",
        "    if self.weight_init == 'random':\n",
        "      for i in range(1, self.hidden_layers + 2):\n",
        "          weight_shape = (self.network_size[i - 1], self.network_size[i])\n",
        "          weight_scale = 0.1\n",
        "          self.weights[f'W{i}'] = np.random.normal(scale=weight_scale, size=weight_shape)*0.1\n",
        "          \n",
        "          bias_shape = (1, self.network_size[i])\n",
        "          self.weights[f'B{i}'] = np.zeros(bias_shape)\n",
        "\n",
        "    if self.weight_init == 'Xavier':\n",
        "      for i in range(1, self.hidden_layers + 2):\n",
        "          weight_shape = (self.network_size[i - 1], self.network_size[i])\n",
        "          weight_scale = 0.1\n",
        "          self.weights[f'W{i}'] = np.random.normal(scale=weight_scale, size=weight_shape)*np.sqrt(1/self.network_size[i-1])\n",
        "          \n",
        "          bias_shape = (1, self.network_size[i])\n",
        "          self.weights[f'B{i}'] = np.zeros(bias_shape)\n",
        "\n",
        "  def forward_activation(self, X):\n",
        "      activation_functions = {\n",
        "          'sigmoid': lambda x: 1.0 / (1.0 + np.exp(-x)),\n",
        "          'tanh': np.tanh,\n",
        "          'Relu': lambda x: np.maximum(0, x)\n",
        "      }\n",
        "      activation_function = activation_functions.get(self.activation_function)\n",
        "      if activation_function:\n",
        "          return activation_function(X)\n",
        "      else:\n",
        "          raise ValueError(f\"Unknown activation function '{self.activation_function}'\")\n",
        "\n",
        "\n",
        "  def grad_activation(self, X):\n",
        "      activation_gradients = {\n",
        "          'sigmoid': lambda x: x * (1 - x),\n",
        "          'tanh': lambda x: 1 - np.square(x),\n",
        "          'Relu': lambda x: 1.0 * (x > 0)\n",
        "      }\n",
        "      gradient_function = activation_gradients.get(self.activation_function)\n",
        "      if gradient_function:\n",
        "          return gradient_function(X)\n",
        "      else:\n",
        "          raise ValueError(f\"Unknown activation function '{self.activation_function}'\")\n",
        "\n",
        "\n",
        "  def softmax(self, X):\n",
        "    exps =np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "    return  exps /np.sum(exps, axis=1, keepdims=True)\n",
        "  \n",
        "\n",
        "  def forward_pass(self, X, weights=None):\n",
        "      if weights is None:\n",
        "          weights = self.weights\n",
        "      self.A = {}\n",
        "      self.H = {}\n",
        "      self.H[0] = X\n",
        "      for i in range(self.hidden_layers):\n",
        "          self.A[i+1] = self.H[i] @ weights[f'W{i+1}'] + weights[f'B{i+1}']\n",
        "          self.H[i+1] = self.forward_activation(self.A[i+1])\n",
        "      self.A[self.hidden_layers+1] = self.H[self.hidden_layers] @ weights[f'W{self.hidden_layers+1}'] + weights[f'B{self.hidden_layers+1}']\n",
        "      self.H[self.hidden_layers+1] = self.softmax(self.A[self.hidden_layers+1])\n",
        "      return self.H[self.hidden_layers+1]\n",
        "\n",
        "  def backprop(self, X, Y, weights=None):\n",
        "    if weights is None:\n",
        "        weights = self.weights\n",
        "\n",
        "    self.forward_pass(X, weights)\n",
        "    self.grad_derivatice = {}\n",
        "    L = self.hidden_layers + 1\n",
        "\n",
        "    if self.loss_function == 'CE':\n",
        "        self.grad_derivatice[f'dA{L}'] = (self.H[L] - Y) * (1/X.shape[0])\n",
        "    elif self.loss_function == 'MSE':\n",
        "        self.grad_derivatice[f'dA{L}'] = (1/X.shape[0]) * 2 * (self.H[L] - Y)\n",
        "\n",
        "    for k in range(L, 0, -1):\n",
        "        w_key, b_key, dw_key, db_key, da_key = [f\"{key}{k}\" for key in ['W', 'B', 'dW', 'dB', 'dA']]\n",
        "        self.grad_derivatice[dw_key] = np.matmul(self.H[k-1].T, self.grad_derivatice[da_key]) + self.lambd * weights[w_key]\n",
        "        self.grad_derivatice[db_key] = np.sum(self.grad_derivatice[da_key], axis=0).reshape(1, -1)\n",
        "        self.grad_derivatice[f'dH{k-1}'] = np.matmul(self.grad_derivatice[da_key], weights[w_key].T)\n",
        "        self.grad_derivatice[f'dA{k-1}'] = np.multiply(self.grad_derivatice[f'dH{k-1}'], self.grad_activation(self.H[k-1]))\n",
        "\n",
        "    return self.grad_derivatice[f'dH{k-1}']\n",
        "\n",
        "  def fit(self, X, Y, X_val, Y_val,algo= 'GD',a = 10, eps=1e-8, beta=0.9, beta1=0.9, beta2=0.9, gamma=0.9 ):\n",
        "    for num_epoch in tqdm(range(1, self.epochs+1), unit='epoch'):\n",
        "      m = X.shape[0]\n",
        "      \n",
        "      if algo == 'SGD':\n",
        "        for i in range(m):\n",
        "            rand_idx = np.random.randint(m)\n",
        "            x_i = X[rand_idx:rand_idx+1]\n",
        "            y_i = Y[rand_idx:rand_idx+1]\n",
        "            self.backprop(x_i, y_i)\n",
        "            for j in range(1, self.hidden_layers+1):\n",
        "              w_key, b_key, dw_key, db_key = [f\"{key}{j}\" for key in ['W', 'B', 'dW', 'dB']]\n",
        "              self.weights[w_key] -=self.learning_rate * self.grad_derivatice[dw_key]\n",
        "              self.weights[b_key] -=self.learning_rate * self.grad_derivatice[db_key]\n",
        "        self.wandlog(num_epoch, X, Y, X_val, Y_val)\n",
        "\n",
        "      elif algo == 'Momentum':\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            self.backprop(X_batch, Y_batch)\n",
        "\n",
        "            for i in range(1, self.hidden_layers+1):\n",
        "              w_key, b_key, vw_key, vb_key,dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "              self.update_weights[vw_key] = gamma *self.update_weights[vw_key] + self.learning_rate * (self.grad_derivatice[dw_key])\n",
        "              self.update_weights[vb_key] = gamma *self.update_weights[vb_key] + self.learning_rate * (self.grad_derivatice[db_key])\n",
        "              self.weights[w_key] -= self.update_weights[vw_key]\n",
        "              self.weights[b_key] -= self.update_weights[vb_key]\n",
        "        self.wandlog(num_epoch, X, Y,X_val, Y_val)\n",
        "\n",
        "      elif algo == 'RMSProp':\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            self.backprop(X_batch, Y_batch)\n",
        "\n",
        "            for i in range(1, self.hidden_layers+1):\n",
        "                w_key, b_key, vw_key, vb_key, dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                self.update_weights[vw_key] = beta * self.update_weights[vw_key] + (1 - beta) * ((self.grad_derivatice[dw_key])**2)\n",
        "                self.update_weights[vb_key] = beta * self.update_weights[vb_key] + (1 - beta) * ((self.grad_derivatice[db_key])**2)\n",
        "                self.weights[w_key] -= (self.learning_rate / (np.sqrt(self.update_weights[vw_key] + eps))) * (self.grad_derivatice[dw_key])\n",
        "                self.weights[b_key] -= (self.learning_rate / (np.sqrt(self.update_weights[vb_key] + eps))) * (self.grad_derivatice[db_key])\n",
        "\n",
        "        self.wandlog(num_epoch, X, Y, X_val, Y_val)\n",
        "      \n",
        "      elif algo == 'Adam':\n",
        "\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            self.backprop(X_batch, Y_batch)\n",
        "\n",
        "            for i in range(1, self.hidden_layers + 1):\n",
        "                w_key, b_key, vw_key, vb_key, mw_key, mb_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'mw', 'mb']]\n",
        "                dw_key, db_key= [f\"{key}{i}\" for key in ['dW', 'dB']]\n",
        "\n",
        "                self.update_weights[mw_key] = beta1 * self.update_weights[mw_key] + (1 - beta1) * self.grad_derivatice[dw_key]\n",
        "                self.update_weights[vw_key] = beta2 * self.update_weights[vw_key] + (1 - beta2) * (self.grad_derivatice[dw_key] ** 2)\n",
        "                mw_hat = self.update_weights[mw_key] / (1 - np.power(beta1, batch + 1))\n",
        "                vw_hat = self.update_weights[vw_key] / (1 - np.power(beta2, batch + 1))\n",
        "                self.weights[w_key] -= (self.learning_rate / np.sqrt(vw_hat + eps)) * mw_hat\n",
        "\n",
        "                self.update_weights[mb_key] = beta1 * self.update_weights[mb_key] + (1 - beta1) * self.grad_derivatice[db_key]\n",
        "                self.update_weights[vb_key] = beta2 * self.update_weights[vb_key] + (1 - beta2) * (self.grad_derivatice[db_key] ** 2)\n",
        "                mb_hat = self.update_weights[mb_key] / (1 - np.power(beta1, batch + 1))\n",
        "                vb_hat = self.update_weights[vb_key] / (1 - np.power(beta2, batch + 1))\n",
        "                self.weights[b_key] -= (self.learning_rate / np.sqrt(vb_hat + eps)) * mb_hat\n",
        "\n",
        "        self.wandlog(num_epoch, X, Y,X_val, Y_val)\n",
        "          \n",
        "      elif algo == 'NAG':\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        temp_weights = {}\n",
        "        for i in range(1, self.hidden_layers+2):\n",
        "          w_key, b_key = [f\"{key}{i}\" for key in ['W', 'B']]\n",
        "          temp_weights[w_key] = np.zeros_like(self.weights[w_key])\n",
        "          temp_weights[b_key] = np.zeros_like(self.weights[b_key])\n",
        "        \n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            for i in range(1,self.hidden_layers+1):\n",
        "                w_key, b_key, vw_key, vb_key,dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                self.update_weights[vw_key]=gamma*self.prev_update_weights[vw_key]\n",
        "                self.update_weights[vb_key]=gamma*self.prev_update_weights[vb_key]\n",
        "                temp_weights[w_key]=self.weights[w_key]-self.update_weights[vw_key]\n",
        "                temp_weights[b_key]=self.weights[b_key]-self.update_weights[vb_key]\n",
        "            self.backprop(X_batch,Y_batch,temp_weights)\n",
        "            for i in range(1,self.hidden_layers+1):\n",
        "                w_key, b_key, vw_key, vb_key,dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                self.update_weights[vw_key] = gamma *self.update_weights[vw_key] + self.learning_rate * (self.grad_derivatice[dw_key])\n",
        "                self.update_weights[vb_key] = gamma *self.update_weights[vb_key] + self.learning_rate * (self.grad_derivatice[db_key])\n",
        "                self.weights[w_key] -= self.learning_rate * (self.update_weights[vw_key])\n",
        "                self.weights[b_key] -= self.learning_rate * (self.update_weights[vb_key]) \n",
        "\n",
        "            self.prev_update_weights=self.update_weights\n",
        "\n",
        "        self.wandlog(num_epoch, X, Y,X_val, Y_val)\n",
        "\n",
        "      elif algo == 'Nadam':\n",
        "\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        num_updates = 0\n",
        "        for i in range(1, self.hidden_layers + 1):\n",
        "            w_key, b_key, vw_key, vb_key, mw_key, mb_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'mw', 'mb']]\n",
        "            dw_key, db_key, mw_i_key, mb_i_key = [f\"{key}{i}\" for key in ['dW', 'dB', 'mw_inf', 'mb_inf']]\n",
        "\n",
        "            for batch in range(num_batches + 1):\n",
        "                start_index = batch *self.batch_size\n",
        "                end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "                X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "                self.backprop(X_batch, Y_batch)\n",
        "\n",
        "                num_updates += 1\n",
        "                self.update_weights.setdefault(mw_i_key, 0)\n",
        "                self.update_weights[mw_key] = beta1 * self.update_weights[mw_key] + (1 - beta1) * (self.grad_derivatice[dw_key] )\n",
        "                self.update_weights[vw_key] = beta2 * self.update_weights[vw_key] + (1 - beta2) * ((self.grad_derivatice[dw_key]) ** 2)\n",
        "                mw_hat = self.update_weights[mw_key] / (1 - np.power(beta1, num_updates))\n",
        "                vw_hat = self.update_weights[vw_key] / (1 - np.power(beta2, num_updates))\n",
        "                mw_inf = beta1 * self.update_weights[mw_i_key] + (1 - beta1) * np.abs(self.grad_derivatice[dw_key])\n",
        "                mw_inf_hat = mw_inf / (1 - np.power(beta1, num_updates))\n",
        "                self.weights[w_key] -= (self.learning_rate / np.sqrt(vw_hat + eps)) * ((beta1 * mw_hat) + ((1 - beta1) * self.grad_derivatice[dw_key])) / (1 - np.power(beta2, num_updates)) + self.learning_rate * eps * np.sqrt(1 - np.power(beta2, num_updates)) * mw_inf_hat\n",
        "\n",
        "                self.update_weights.setdefault(mb_i_key, 0)\n",
        "                self.update_weights[mb_key] = beta1 * self.update_weights[mb_key] + (1 - beta1) * (self.grad_derivatice[db_key])\n",
        "                self.update_weights[vb_key] = beta2 * self.update_weights[vb_key] + (1 - beta2) * ((self.grad_derivatice[db_key]) ** 2)\n",
        "                mb_hat = self.update_weights[mb_key] / (1 - np.power(beta1, num_updates))\n",
        "                vb_hat = self.update_weights[vb_key] / (1 - np.power(beta2, num_updates))\n",
        "                mb_inf = beta1 * self.update_weights[mb_i_key] + (1 - beta1) * np.abs(self.grad_derivatice[db_key])\n",
        "                mb_inf_hat = mb_inf / (1 - np.power(beta1, num_updates))\n",
        "                self.weights[b_key] -= (self.learning_rate / np.sqrt(vb_hat + eps)) * ((beta1 * mb_hat) + ((1 - beta1) * self.grad_derivatice[db_key])) / (1 - np.power(beta2, num_updates)) + self.learning_rate * eps * np.sqrt(1 - np.power(beta2, num_updates)) * mb_inf\n",
        "        self.wandlog(num_epoch, X, Y,X_val, Y_val)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = (self.forward_pass(X))\n",
        "    return np.array(Y_pred).squeeze()\n",
        "  \n",
        "  def accuracy_score(self, X, Y):\n",
        "    Y_true = np.argmax(Y, axis=1).reshape(-1, 1)\n",
        "    pred_labels = np.argmax(self.predict(X), axis=1).reshape(-1,1)\n",
        "    return np.sum(pred_labels == Y_true) / len(Y)\n",
        "\n",
        "  def Loss(self, X, Y):\n",
        "    Y_pred = self.predict(X)\n",
        "    if self.loss_function== 'CE':\n",
        "        loss = -np.mean(Y * np.log(Y_pred + 1e-8))\n",
        "    elif self.loss_function == 'MSE':\n",
        "        loss = np.mean((Y - Y_pred)**2)\n",
        "    return loss\n",
        "\n",
        "  def performance(self, X_test, Y_test):\n",
        "    loss = self.Loss(X_test, Y_test)\n",
        "    accuracy = self.accuracy_score(X_test, Y_test)\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "  def confusion_matrix(self, X, Y):\n",
        "\n",
        "      actual_labels = np.argmax(Y, axis=1)\n",
        "      predicted_labels = np.argmax(self.forward_pass(X), axis=1)\n",
        "\n",
        "\n",
        "      available_classes = np.unique(np.concatenate((actual_labels, predicted_labels)))\n",
        "\n",
        "      confusion_matrix_ = np.zeros((len(available_classes), len(available_classes)), dtype=int)\n",
        "      for i, actual in enumerate(available_classes):\n",
        "          for j, predicted in enumerate(available_classes):\n",
        "              confusion_matrix_[i,j] = np.where((actual_labels == actual) & (predicted_labels == predicted))[0].shape[0]\n",
        "      wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "          probs=None,\n",
        "          y_true=actual_labels,\n",
        "          preds=predicted_labels,\n",
        "          class_names=list(available_classes),\n",
        "          title=\"Confusion Matrix\"\n",
        "      )})\n",
        "\n",
        "      return confusion_matrix_\n",
        "\n",
        "\n",
        "\n",
        "  def confusion_matrix_plot(self, confusion_matrix, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
        "    confusion_matrix = confusion_matrix/10\n",
        "    plt.matshow(confusion_matrix, cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(confusion_matrix))\n",
        "    plt.xticks(tick_marks)\n",
        "    plt.yticks(tick_marks)\n",
        "    plt.ylabel('actual')\n",
        "    plt.xlabel('predicted')\n",
        "\n",
        "\n",
        "  def wandlog(self, num_epoch, X, Y,X_val, Y_val):\n",
        "    accuracy = self.accuracy_score(X, Y)\n",
        "    loss_train = self.Loss(X, Y)\n",
        "    loss_valid = self.Loss(X_val, Y_val)\n",
        "    val_accuracy = self.accuracy_score(X_val, Y_val)\n",
        "    wandb.log({'epoch': num_epoch,           \n",
        "              'loss': loss_train,\n",
        "              'accuracy': accuracy,\n",
        "              'val_loss': loss_valid,\n",
        "              'val_accuracy': val_accuracy})\n",
        "    \n",
        "    if num_epoch % 5== 0:\n",
        "      accuracy = self.accuracy_score(X, Y)\n",
        "      loss_train = self.Loss(X, Y)\n",
        "      loss_valid = self.Loss(X_val, Y_val)\n",
        "      val_accuracy = self.accuracy_score(X_val, Y_val)\n",
        "      library = {'epoch': num_epoch,           \n",
        "              'loss': loss_train,\n",
        "              'accuracy': accuracy,\n",
        "              'val_loss': loss_valid,\n",
        "              'val_accuracy': val_accuracy}\n",
        "\n",
        "      print('Epoch: {}, Train Loss: {}, Train Accuracy: {}, Val Loss: {}, Val Accuracy: {}'.format(library['epoch'], library['loss'], library['accuracy'], library['val_loss'], library['val_accuracy']))\n",
        "      if num_epoch == self.epochs:\n",
        "        print('Model trained successfully !')\n",
        "    \n",
        "  \n",
        "# import itertools\n",
        "# #X_train, X_val, X_test, Y_train, Y_val, Y_test = X_train[0:10, :], X_val[0:10, :], X_test[0:10, :], Y_train[0:10, :], Y_val[0:10, :], Y_test[0:10, :]\n",
        "\n",
        "# algos = ['SGD','Momentum', 'NAG',  'RMSProp', 'Adam', 'Nadam']\n",
        "# init_method = ['random', 'Xavier']\n",
        "# loss = ['CE', 'MSE']\n",
        "# activation = ['sigmoid', 'tanh', 'Relu']\n",
        "# c = 0\n",
        "# for algo, init, loss_fn, act in itertools.product(algos, init_method, loss, activation):\n",
        "#   print(algo, init, loss_fn, act)\n",
        "#   model = FFNetwork(X_train, Y_train,\n",
        "#                     epochs=1,\n",
        "#                     hidden_layer_count=1,\n",
        "#                     hidden_layers=[1],\n",
        "#                     learning_rate=0.001,\n",
        "#                     batch_size=128,\n",
        "#                     activation=act,\n",
        "#                     weight_init=init,\n",
        "#                     loss=loss_fn)\n",
        "#   model.fit(X_train, Y_train, X_val, Y_val, algo=algo)\n",
        "#   confusion_matrix = model.confusion_matrix(X_test, Y_test)\n",
        "#   print(confusion_matrix.shape)\n",
        "#   print(model.accuracy_score(X_test, Y_test))\n",
        "#   #model.confusion_matrix_plot(confusion_matrix)\n",
        "#   c = c + 1\n",
        "# print(c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Function"
      ],
      "metadata": {
        "id": "vRcqIRGif5Lr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "43dd0c6f6cfa47a89a0189cf39b3f242",
            "990e91b0d76a4e3998df110b307ff1f2",
            "538398a6819b46c08308780630df99ab",
            "541541d02bf14f97b5fb056cd1e8c512",
            "76649ac782544ef1a3d19cfab9b7ca3c",
            "a4ea43fa534444099257b45fd88f5481",
            "5ed775f208f441989010a9ee615c2b8b",
            "37af43979ab0457fa754a22dff0288ac",
            "a90e6162224f457cb156d08faf37439c",
            "7fc427f1ccb34a33b479f2c1cbcfcd22",
            "91ea4f4b1a184664928b00e199274018"
          ]
        },
        "id": "3IEJg4fnyEIj",
        "outputId": "01863b31-d5a2-40ef-98d6-4eafb1201604"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:u79hb07r) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁█▁▁█▁█▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁█▁█▁▁█▁█▁▁█▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▁▁█▁▁██▁██▁▁█▁▁██▁██▁▁█▁▁██▁██▁██▁▁█▁▁</td></tr><tr><td>val_accuracy</td><td>▁█▁▁█▁█▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁█▁█▁▁█▁█▁▁█▁▁</td></tr><tr><td>val_loss</td><td>██▁▁█▁▁██▁██▁▁█▁▁██▁██▁▁█▁▁██▁██▁██▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.10354</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.08748</td></tr><tr><td>val_accuracy</td><td>0.10133</td></tr><tr><td>val_loss</td><td>0.0876</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">noble-bush-5</strong> at: <a href='https://wandb.ai/ed22s009/Question_5/runs/u79hb07r' target=\"_blank\">https://wandb.ai/ed22s009/Question_5/runs/u79hb07r</a><br/>Synced 5 W&B file(s), 72 media file(s), 72 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230306_045334-u79hb07r/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:u79hb07r). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230306_050211-mo8k7p6b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed22s009/Question_4/runs/mo8k7p6b' target=\"_blank\">driven-field-65</a></strong> to <a href='https://wandb.ai/ed22s009/Question_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed22s009/Question_4' target=\"_blank\">https://wandb.ai/ed22s009/Question_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed22s009/Question_4/runs/mo8k7p6b' target=\"_blank\">https://wandb.ai/ed22s009/Question_4/runs/mo8k7p6b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:mo8k7p6b) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">driven-field-65</strong> at: <a href='https://wandb.ai/ed22s009/Question_4/runs/mo8k7p6b' target=\"_blank\">https://wandb.ai/ed22s009/Question_4/runs/mo8k7p6b</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230306_050211-mo8k7p6b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:mo8k7p6b). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230306_050216-giv47piu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed22s009/confusion_matrix/runs/giv47piu' target=\"_blank\">dandy-pyramid-83</a></strong> to <a href='https://wandb.ai/ed22s009/confusion_matrix' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed22s009/confusion_matrix' target=\"_blank\">https://wandb.ai/ed22s009/confusion_matrix</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed22s009/confusion_matrix/runs/giv47piu' target=\"_blank\">https://wandb.ai/ed22s009/confusion_matrix/runs/giv47piu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:giv47piu) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dandy-pyramid-83</strong> at: <a href='https://wandb.ai/ed22s009/confusion_matrix/runs/giv47piu' target=\"_blank\">https://wandb.ai/ed22s009/confusion_matrix/runs/giv47piu</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230306_050216-giv47piu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:giv47piu). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230306_050220-f4ltg12z</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed22s009/confusion_matrix/runs/f4ltg12z' target=\"_blank\">elated-brook-84</a></strong> to <a href='https://wandb.ai/ed22s009/confusion_matrix' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed22s009/confusion_matrix' target=\"_blank\">https://wandb.ai/ed22s009/confusion_matrix</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed22s009/confusion_matrix/runs/f4ltg12z' target=\"_blank\">https://wandb.ai/ed22s009/confusion_matrix/runs/f4ltg12z</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?epoch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43dd0c6f6cfa47a89a0189cf39b3f242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Train Loss: 0.04396666790707658, Train Accuracy: 0.8471851851851852, Val Loss: 0.04529196324252498, Val Accuracy: 0.8413333333333334\n",
            "Epoch: 10, Train Loss: 0.03438723153359152, Train Accuracy: 0.8752962962962964, Val Loss: 0.03738092948795063, Val Accuracy: 0.8666666666666667\n",
            "Model trained successfully !\n",
            "[[759   1   9  48   6   3 156   0  18   0]\n",
            " [  3 953   4  30   6   0   2   0   2   0]\n",
            " [ 10   2 693   8 169   0 108   0   9   1]\n",
            " [ 20   6   9 863  61   1  29   0  11   0]\n",
            " [  0   0  70  19 840   0  65   0   6   0]\n",
            " [  0   0   0   0   0 962   0  21   2  15]\n",
            " [106   1  83  32 105   0 649   0  24   0]\n",
            " [  0   0   0   0   0  45   0 936   0  19]\n",
            " [  0   0   1   5   6   6  10   5 967   0]\n",
            " [  0   0   0   0   0  24   1  49   0 926]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8753</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.03439</td></tr><tr><td>val_accuracy</td><td>0.86667</td></tr><tr><td>val_loss</td><td>0.03738</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">elated-brook-84</strong> at: <a href='https://wandb.ai/ed22s009/confusion_matrix/runs/f4ltg12z' target=\"_blank\">https://wandb.ai/ed22s009/confusion_matrix/runs/f4ltg12z</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230306_050220-f4ltg12z/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "wandb.init(project = 'Question_4')\n",
        "\n",
        "algos = ['GD','SGD', 'MiniBatch', 'Momentum', 'NAG', 'AdaGrad', 'RMSProp', 'Adam','Nadam']\n",
        "configuration = {\n",
        "    'learning_rate': 0.001,\n",
        "    'epochs': 10,\n",
        "    'hidden_layer_count': 3,\n",
        "    'size_hidden_layers': 128,\n",
        "    'optimizer': 'Adam',\n",
        "    'batch_size': 128,\n",
        "    'activation': 'Relu',\n",
        "    'weight_initializations': 'Xavier',\n",
        "    'weight_decay': 0,\n",
        "    'loss_function': 'CE',\n",
        "}\n",
        "\n",
        "def train():\n",
        "  \n",
        "  wandb.init(project ='confusion_matrix',config=configuration, magic=True,reinit = True)\n",
        "  wandb.run.name = '/batch_size/'+str(wandb.config.batch_size)+'/learning_rate/'+ str(wandb.config.learning_rate)+'/epochs/'+str(wandb.config.epochs)+ '/optimizer/'+str(wandb.config.optimizer)+ '/hidden_layer_count/'+str(wandb.config.hidden_layer_count)+'/size_hidden_layers/'+str(wandb.config.size_hidden_layers)+ '/activation/'+str(wandb.config.activation)+'/weight_decay/'+str(wandb.config.weight_decay)+'/weight_initializations/'+str(wandb.config.weight_initializations)+'/loss_function/'+str(wandb.config.loss_function)\n",
        "\n",
        "  \n",
        "  # [configuration['size_hidden_layers']] * configuration['hidden_layer_count']\n",
        "\n",
        "  hidden_layer_count = wandb.config.hidden_layer_count \n",
        "  size_hidden_layers = wandb.config.size_hidden_layers \n",
        "  model = FFNetwork(X_train, Y_train,\n",
        "                epochs = wandb.config.epochs, \n",
        "                hidden_layer_count =  wandb.config.hidden_layer_count,\n",
        "                hidden_layers = [size_hidden_layers]*hidden_layer_count,\n",
        "                learning_rate = wandb.config.learning_rate,\n",
        "                batch_size = wandb.config.batch_size,\n",
        "                activation=wandb.config.activation,\n",
        "                weight_init=wandb.config.weight_initializations,\n",
        "                loss = wandb.config.loss_function,\n",
        "                weight_decay = wandb.config.weight_decay)\n",
        "\n",
        "  algos = ['GD','SGD', 'MiniBatch', 'Momentum', 'NAG', 'AdaGrad', 'RMSProp', 'Adam','Nadam']\n",
        "  ['momentum','sgd','rmsprop','nesterov','adam','nadam']\n",
        "  optimizer = wandb.config.optimizer\n",
        "  if optimizer == 'SGD':\n",
        "    weights = model.fit(X_train, Y_train, X_val, Y_val, algo= 'SGD')\n",
        "  elif optimizer == 'Momentum':\n",
        "    weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'Momentum')\n",
        "  elif optimizer == 'NAG':\n",
        "    weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'NAG')\n",
        "  elif optimizer == 'RMSProp':\n",
        "    weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'RMSProp')\n",
        "  elif optimizer == 'Adam':\n",
        "    weights =model.fit(X_train, Y_train, X_val, Y_val, algo='Adam')\n",
        "  elif optimizer =='nadam':\n",
        "    weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'Nadam')\n",
        "  else:\n",
        "    print('Invalid optimizer')\n",
        "\n",
        "\n",
        "\n",
        "  confusion_matrix = model.confusion_matrix(X_test, Y_test)\n",
        "  print(confusion_matrix)\n",
        "  model.confusion_matrix_plot(confusion_matrix)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  train()\n",
        "  wandb.finish()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_dP0oEKrgmQc",
        "NiqBs52vjT6P",
        "j80rnJZjjYxh",
        "vRcqIRGif5Lr"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43dd0c6f6cfa47a89a0189cf39b3f242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_990e91b0d76a4e3998df110b307ff1f2",
              "IPY_MODEL_538398a6819b46c08308780630df99ab",
              "IPY_MODEL_541541d02bf14f97b5fb056cd1e8c512"
            ],
            "layout": "IPY_MODEL_76649ac782544ef1a3d19cfab9b7ca3c"
          }
        },
        "990e91b0d76a4e3998df110b307ff1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ea43fa534444099257b45fd88f5481",
            "placeholder": "​",
            "style": "IPY_MODEL_5ed775f208f441989010a9ee615c2b8b",
            "value": "100%"
          }
        },
        "538398a6819b46c08308780630df99ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37af43979ab0457fa754a22dff0288ac",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a90e6162224f457cb156d08faf37439c",
            "value": 10
          }
        },
        "541541d02bf14f97b5fb056cd1e8c512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc427f1ccb34a33b479f2c1cbcfcd22",
            "placeholder": "​",
            "style": "IPY_MODEL_91ea4f4b1a184664928b00e199274018",
            "value": " 10/10 [00:44&lt;00:00,  4.77s/epoch]"
          }
        },
        "76649ac782544ef1a3d19cfab9b7ca3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ea43fa534444099257b45fd88f5481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed775f208f441989010a9ee615c2b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37af43979ab0457fa754a22dff0288ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90e6162224f457cb156d08faf37439c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fc427f1ccb34a33b479f2c1cbcfcd22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ea4f4b1a184664928b00e199274018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}