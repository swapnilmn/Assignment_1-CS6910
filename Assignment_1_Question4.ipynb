{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnilmn/Assignment_1_CS6910/blob/master/Assignment_1_Question4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Q5opYMgYb-"
      },
      "source": [
        "# Question 4 (10 Marks) Use the sweep functionality provided by wandb to find the best values for the hyperparameters listed below. Use the standard train/test split of fashion_mnist (use (X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()). Keep 10% of the training data aside as validation data for this hyperparameter search. Here are some suggestions for different values to try for hyperparameters. As you can quickly see that this leads to an exponential number of combinations. You will have to think about strategies to do this hyperparameter search efficiently. Check out the options provided by wandb.sweep and write down what strategy you chose and why.\n",
        "\n",
        "        number of epochs: 5, 10\n",
        "        number of hidden layers: 3, 4, 5\n",
        "        size of every hidden layer: 32, 64, 128\n",
        "        weight decay (L2 regularisation): 0, 0.0005, 0.5\n",
        "        learning rate: 1e-3, 1 e-4\n",
        "        optimizer: sgd, momentum, nesterov, rmsprop, adam, nadam\n",
        "        batch size: 16, 32, 64\n",
        "        weight initialisation: random, Xavier\n",
        "        activation functions: sigmoid, tanh, ReLU\n",
        "wandb will automatically generate the following plots. Paste these plots below using the \"Add Panel to Report\" feature. Make sure you use meaningful names for each sweep (e.g. hl_3_bs_16_ac_tanh to indicate that there were 3 hidden layers, batch size was 16 and activation function was ReLU) instead of using the default names (whole-sweep, kind-sweep) given by wandb."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "xboPT1_6SUoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf Assignment_1_CS6910\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!git config --global credential.helper 'cache --timeout=3600'\n",
        "!git clone https://swapnilmn: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@github.com/swapnilmn/Assignment_1_CS6910.git\n",
        "\n",
        "!pip install import_ipynb\n",
        "import import_ipynb\n",
        "from Assignment_1_CS6910 import Question_3 as NN\n",
        "from Assignment_1_CS6910.Question_3 import FFNN\n",
        "\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gOOsP9ilgIUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18d7e61-1be0-4c02-ba18-797b87b333e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Assignment_1_CS6910' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.9/dist-packages (0.1.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from import_ipynb) (5.7.3)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.9/dist-packages (from import_ipynb) (7.9.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (63.4.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (2.0.10)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from IPython->import_ipynb) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.9/dist-packages (from nbformat->import_ipynb) (5.2.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->import_ipynb) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core->nbformat->import_ipynb) (3.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.14.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.17.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Function"
      ],
      "metadata": {
        "id": "vRcqIRGif5Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Question_4_Best_Model', entity = 'ed22s009')\n",
        "\n",
        "configuration = {\n",
        "    'learning_rate': 0.001,\n",
        "    'epochs': 18,\n",
        "    'hidden_layer_count': 3,\n",
        "    'size_hidden_layers': 256,\n",
        "    'optimizer': 'nadam',\n",
        "    'batch_size': 128,\n",
        "    'activation': 'tanh',\n",
        "    'weight_initializations': 'Xavier',\n",
        "    'weight_decay': 0,\n",
        "    'loss_function': 'cross_entropy',\n",
        "    'dataset': 'fashion_mnist'#, 'mnist'\n",
        "}\n",
        "def train():\n",
        "  np.random.seed(0)\n",
        "  \n",
        "  wandb.init(project ='confusion_matrix',config=configuration)\n",
        "  config_dict = {\n",
        "    'batch_size': wandb.config.batch_size,\n",
        "    'learning_rate': wandb.config.learning_rate,\n",
        "    'epochs': wandb.config.epochs,\n",
        "    'optimizer': wandb.config.optimizer,\n",
        "    'hidden_layer_count': wandb.config.hidden_layer_count,\n",
        "    'size_hidden_layers': wandb.config.size_hidden_layers,\n",
        "    'activation': wandb.config.activation,\n",
        "    'weight_decay': wandb.config.weight_decay,\n",
        "    'weight_initializations': wandb.config.weight_initializations,\n",
        "    'loss_function': wandb.config.loss_function\n",
        "     }\n",
        "  wandb.run.name = '/'.join([f'{k}/{v}' for k, v in config_dict.items()])\n",
        "\n",
        "\n",
        "  X_train, X_val, X_test, Y_train, Y_val, Y_test = NN.dataset_type(dataset=wandb.config.dataset)\n",
        "\n",
        "  model = FFNN(X_train, Y_train,\n",
        "                  epochs=wandb.config.epochs,\n",
        "                  hidden_layer_count=wandb.config.hidden_layer_count,\n",
        "                  hidden_layers=[wandb.config.size_hidden_layers]*wandb.config.hidden_layer_count,\n",
        "                  learning_rate=wandb.config.learning_rate,\n",
        "                  batch_size=wandb.config.batch_size,\n",
        "                  activation=wandb.config.activation,\n",
        "                  weight_init=wandb.config.weight_initializations,\n",
        "                  loss=wandb.config.loss_function,\n",
        "                  weight_decay=wandb.config.weight_decay)\n",
        "\n",
        "\n",
        "  optimizers = {\n",
        "      'sgd': 'sgd',\n",
        "      'momentum': 'momentum',\n",
        "      'nag': 'nag',\n",
        "      'rmsprop': 'rmsprop',\n",
        "      'adam': 'adam',\n",
        "      'nadam': 'nadam'\n",
        "  }\n",
        "\n",
        "  optimizer = wandb.config.optimizer\n",
        "  if optimizer in optimizers:\n",
        "      weights = model.fit(X_train, Y_train, X_val, Y_val, algo=optimizers[optimizer])\n",
        "  else:\n",
        "      print('Invalid optimizer')\n",
        "\n",
        "  print(model.confusion_matrix(X_test, Y_test))\n",
        "  model.confo_matrixplot(model.confusion_matrix(X_test, Y_test))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # train()\n",
        "  wandb.finish()\n"
      ],
      "metadata": {
        "id": "9ul8IvvqUSss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2db57992-5d8b-47be-b4e3-1b7eb679b67e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230318_012502-5tuu985h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed22s009/Question_4_Best_Model/runs/5tuu985h' target=\"_blank\">autumn-bird-873</a></strong> to <a href='https://wandb.ai/ed22s009/Question_4_Best_Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed22s009/Question_4_Best_Model' target=\"_blank\">https://wandb.ai/ed22s009/Question_4_Best_Model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed22s009/Question_4_Best_Model/runs/5tuu985h' target=\"_blank\">https://wandb.ai/ed22s009/Question_4_Best_Model/runs/5tuu985h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">autumn-bird-873</strong> at: <a href='https://wandb.ai/ed22s009/Question_4_Best_Model/runs/5tuu985h' target=\"_blank\">https://wandb.ai/ed22s009/Question_4_Best_Model/runs/5tuu985h</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230318_012502-5tuu985h/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sweeping the model"
      ],
      "metadata": {
        "id": "6jv4mfHTf8WE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TOrrjwZyTR3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import wandb\n",
        "    wandb_available = True\n",
        "except ImportError:\n",
        "    wandb_available = False\n",
        "\n",
        "if wandb_available:\n",
        "    sweep_config = {\n",
        "        'method': 'bayes',\n",
        "        'name': 'Assignement1',\n",
        "        'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
        "        'parameters': {\n",
        "          'epochs': {'values': [10, 15, 20]},#150\n",
        "          'hidden_layer_count':{'values': [3, 4, 5]},\n",
        "          'size_hidden_layers':{'values': [32,128, 256, 512]},\n",
        "          'learning_rate':{'values': [0.001, 0.0001]},\n",
        "          'optimizer':{'values': [\"sgd\", \"momentum\", \"nag\", \"rmsprop\", \"adam\", \"nadam\"]},\n",
        "          'batch_size':{'values': [32, 64, 128]},\n",
        "          'activation':{'values': ['sigmoid','tanh', 'ReLU']},\n",
        "          'weight_initializations':{'values': ['random','Xavier']},\n",
        "          'weight_decay':{'values': [0, 0.05,0.0005 ]}}\n",
        "        }\n",
        "     \n",
        "\n",
        "    # Create the sweep and run the training function\n",
        "    sweep_id = wandb.sweep(sweep_config, project='Question_4_Best_Model', entity = 'ed22s009')\n",
        "    wandb.agent(sweep_id, function=train)\n",
        "else:\n",
        "    print('wandb library not available')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rough Work"
      ],
      "metadata": {
        "id": "A9_QYxrqAqFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project = 'Question_4_Best_Model', entity = 'ed22s009')\n",
        "\n",
        "# algos = ['GD','SGD', 'MiniBatch', 'Momentum', 'NAG', 'AdaGrad', 'RMSProp', 'Adam','Nadam']\n",
        "# configuration = {\n",
        "#     'learning_rate': 0.001,\n",
        "#     'epochs': 2,\n",
        "#     'hidden_layer_count': 3,\n",
        "#     'size_hidden_layers': 128,\n",
        "#     'optimizer': 'adam',\n",
        "#     'batch_size': 128,\n",
        "#     'activation': 'ReLU',\n",
        "#     'weight_initializations': 'Xavier',\n",
        "#     'weight_decay': 0,\n",
        "#     'loss_function': 'cross_entropy',\n",
        "#     'dataset': 'fashion_mnist'#, \"mnist\"\n",
        "# }\n",
        "\n",
        "# def train():\n",
        "  \n",
        "#   wandb.init(project ='confusion_matrix',config=configuration)\n",
        "#   wandb.run.name = '/batch_size/'+str(wandb.config.batch_size)+'/learning_rate/'+ str(wandb.config.learning_rate)+'/epochs/'+str(wandb.config.epochs)+ '/optimizer/'+str(wandb.config.optimizer)+ '/hidden_layer_count/'+str(wandb.config.hidden_layer_count)+'/size_hidden_layers/'+str(wandb.config.size_hidden_layers)+ '/activation/'+str(wandb.config.activation)+'/weight_decay/'+str(wandb.config.weight_decay)+'/weight_initializations/'+str(wandb.config.weight_initializations)+'/loss_function/'+str(wandb.config.loss_function)\n",
        "\n",
        "  \n",
        "#   # [configuration['size_hidden_layers']] * configuration['hidden_layer_count']\n",
        "#   X_train, X_val, X_test, Y_train, Y_val, Y_test = NN.dataset_type(dataset = wandb.config.dataset)\n",
        "#   hidden_layer_count = wandb.config.hidden_layer_count \n",
        "#   size_hidden_layers = wandb.config.size_hidden_layers \n",
        "#   model = FFNN(X_train, Y_train,\n",
        "#                 epochs = wandb.config.epochs, \n",
        "#                 hidden_layer_count =  wandb.config.hidden_layer_count,\n",
        "#                 hidden_layers = [size_hidden_layers]*hidden_layer_count,\n",
        "#                 learning_rate = wandb.config.learning_rate,\n",
        "#                 batch_size = wandb.config.batch_size,\n",
        "#                 activation=wandb.config.activation,\n",
        "#                 weight_init=wandb.config.weight_initializations,\n",
        "#                 loss = wandb.config.loss_function,\n",
        "#                 weight_decay = wandb.config.weight_decay)\n",
        "\n",
        "#   algos = ['GD','SGD', 'MiniBatch', 'Momentum', 'NAG', 'AdaGrad', 'RMSProp', 'Adam','Nadam']\n",
        "#   [\"sgd\", \"momentum\", \"nag\", \"rmsprop\", \"adam\", \"nadam\"]\n",
        "#   ['momentum','sgd','rmsprop','nesterov','adam','nadam']\n",
        "#   optimizer = wandb.config.optimizer\n",
        "#   if optimizer == 'sgd':\n",
        "#     weights = model.fit(X_train, Y_train, X_val, Y_val, algo= 'sgd')\n",
        "#   elif optimizer == 'momentum':\n",
        "#     weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'momentum')\n",
        "#   elif optimizer == 'nag':\n",
        "#     weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'nag')\n",
        "#   elif optimizer == 'rmsprop':\n",
        "#     weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'rmsprop')\n",
        "#   elif optimizer == 'adam':\n",
        "#     weights =model.fit(X_train, Y_train, X_val, Y_val, algo='adam')\n",
        "#   elif optimizer =='nadam':\n",
        "#     weights =model.fit(X_train, Y_train, X_val, Y_val, algo= 'nadam')\n",
        "#   else:\n",
        "#     print('Invalid optimizer')\n",
        "\n",
        "\n",
        "\n",
        "#   confusion_matrix = model.confusion_matrix(X_test, Y_test)\n",
        "#   print(confusion_matrix)\n",
        "#   model.confo_matrixplot(confusion_matrix)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#   train()\n",
        "#   wandb.finish()\n"
      ],
      "metadata": {
        "id": "waHc4HCyp6Av"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project = 'Question_Best_Model', entity = 'ed22s009')\n",
        "# init_methods = ['random', 'Xavier']\n",
        "# activation_functions = ['sigmoid', 'tanh', 'ReLU']\n",
        "# algos = ['sgd', 'momentum', 'nag', 'rmsprop', 'adam','nadam']\n",
        "# losses = ['cross_entropy', 'mean_squared_error']\n",
        "# c = 0\n",
        "# d = 0\n",
        "# for init_method in init_methods:\n",
        "#     for activation_function in activation_functions:\n",
        "#         for algo in algos:\n",
        "#           for loss in losses:\n",
        "\n",
        "#             model = FFNN(NN.X_train, NN.Y_train,\n",
        "#                           epochs = 1, \n",
        "#                           hidden_layer_count = 1,\n",
        "#                           hidden_layers =  [10],\n",
        "#                           learning_rate = 0.0001,\n",
        "#                           batch_size = 32,\n",
        "#                           activation=activation_function,\n",
        "#                           weight_init=init_method,\n",
        "#                           loss = loss,\n",
        "#                           weight_decay = 0.0005)\n",
        "#             model.fit(NN.X_train, NN.Y_train, NN.X_val, NN.Y_val,algo= algo)\n",
        "#             c = c + 1\n",
        "\n",
        "#             print(c)"
      ],
      "metadata": {
        "id": "lXzNOxRqtARt"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_dP0oEKrgmQc",
        "NiqBs52vjT6P",
        "j80rnJZjjYxh",
        "qvCdYtjPjesY",
        "Jf9807PEjrL_",
        "3QuoMWx3kp11"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPHPK/NXm8O/wYE51QWUl1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}