{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaEW6VhfUOu0+NV0f83y+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70f331a728b24d349ea2c02f4b364edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_847d9cca13a144bdbbef2a11826f06f9",
              "IPY_MODEL_9ed905f8a7fd40a6941d716cfd54c392"
            ],
            "layout": "IPY_MODEL_7652a756a0b947b4b38c17103a84a06b"
          }
        },
        "847d9cca13a144bdbbef2a11826f06f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d5313c50fe47808d263436334e2620",
            "placeholder": "​",
            "style": "IPY_MODEL_1e3ec0c241c54c3092952f2361990cdb",
            "value": "0.001 MB of 0.023 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9ed905f8a7fd40a6941d716cfd54c392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a44b519136d4b57ad1af041ee1625d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7da444e86e0a4a5db1db32e32d036b8b",
            "value": 0.04398593789235791
          }
        },
        "7652a756a0b947b4b38c17103a84a06b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d5313c50fe47808d263436334e2620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3ec0c241c54c3092952f2361990cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a44b519136d4b57ad1af041ee1625d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da444e86e0a4a5db1db32e32d036b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54902b545bbc4fba888c9ae3972cbffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd0a438292c94757839f84405d243c1f",
              "IPY_MODEL_c8d832bc4c6445448d31924fe2e2faa6",
              "IPY_MODEL_a72db58376a542d691c8732d7cd644d4"
            ],
            "layout": "IPY_MODEL_68e7ea312ea245fc9e8ad0d857a973aa"
          }
        },
        "bd0a438292c94757839f84405d243c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8045b97320f94de89589b77980eaf63e",
            "placeholder": "​",
            "style": "IPY_MODEL_8eac1188d32b45ed80e3ccec2708e739",
            "value": "100%"
          }
        },
        "c8d832bc4c6445448d31924fe2e2faa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68e70d0e0ae403bae2f30a52bd3d111",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cbf9e346aee4aa795cce5bbfd93f64b",
            "value": 19
          }
        },
        "a72db58376a542d691c8732d7cd644d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6871900a4b0f458e8d112cf15ba9b942",
            "placeholder": "​",
            "style": "IPY_MODEL_b1699aeb55e74ef594ae87e22d45a91a",
            "value": " 19/19 [10:09&lt;00:00, 31.99s/epoch]"
          }
        },
        "68e7ea312ea245fc9e8ad0d857a973aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8045b97320f94de89589b77980eaf63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eac1188d32b45ed80e3ccec2708e739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68e70d0e0ae403bae2f30a52bd3d111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbf9e346aee4aa795cce5bbfd93f64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6871900a4b0f458e8d112cf15ba9b942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1699aeb55e74ef594ae87e22d45a91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnilmn/Assignment_1_CS6910/blob/master/Question_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 3 (24 Marks) Implement the backpropagation algorithm with support for the following optimisation functions\n",
        "            sgd\n",
        "            momentum based gradient descent\n",
        "            nesterov accelerated gradient descent\n",
        "            rmsprop\n",
        "            adam\n",
        "            nadam\n",
        "\n",
        "(12 marks for the backpropagation framework and 2 marks for each of the optimisation algorithms above)\n",
        "\n",
        "We will check the code for implementation and ease of use (e.g., how easy it is to add a new optimisation algorithm such as Eve). Note that the code should be flexible enough to work with different batch sizes."
      ],
      "metadata": {
        "id": "3kVFZwNkEA7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries "
      ],
      "metadata": {
        "id": "_dP0oEKrgmQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CZcFz8GygBp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "46505a26-52f7-4b72-c133-a45fbb28e2ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist, mnist\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pandas as pd\n",
        "import subprocess\n",
        "subprocess.call(['pip', 'install', 'wandb'])\n",
        "import wandb\n",
        "wandb.login()\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "W-FlxB4-gnqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotEncoder_from_scratch:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.categories = None\n",
        "    def fit(self, X):\n",
        "        self.categories =[]\n",
        "        for i in range(X.shape[1]):\n",
        "            feature_categories =list(set(X[:, i]))\n",
        "            self.categories.append(feature_categories)\n",
        "            \n",
        "    def transform(self, X):\n",
        "        one_hot_vector = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            one_hot_row = []\n",
        "            for j in range(X.shape[1]):\n",
        "\n",
        "                category_index = self.categories[j].index(X[i, j])\n",
        "                category_one_hot =[0] *len(self.categories[j])\n",
        "                category_one_hot[category_index] = 1\n",
        "\n",
        "                one_hot_row.extend(category_one_hot)\n",
        "            one_hot_vector.append(one_hot_row)\n",
        "        return np.array(one_hot_vector)"
      ],
      "metadata": {
        "id": "YTDGKrnOgGwK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_type(dataset = 'fashion_mnist'):\n",
        "  if dataset == 'fashion_mnist':\n",
        "      (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "  elif dataset == 'mnist':\n",
        "      (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "  else:\n",
        "      raise ValueError('Invalid dataset name')\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels, test_size=0.1, random_state=0)\n",
        "  # Flatten input images\n",
        "  train_input = X_train.reshape((X_train.shape[0], -1))\n",
        "  test_input =test_images.reshape((test_images.shape[0], -1))\n",
        "  val_input = X_val.reshape((X_val.shape[0], -1))\n",
        "\n",
        "  Y_train = np.array(Y_train)\n",
        "  Y_val = np.array(Y_val)\n",
        "  Y_test= np.array(test_labels)\n",
        "\n",
        "  X_train =np.array(train_input) / 255.0\n",
        "  X_test = np.array(test_input) / 255.0\n",
        "  X_val = np.array(val_input) / 255.0\n",
        "\n",
        "  enc = OneHotEncoder_from_scratch()\n",
        "  enc.fit(Y_train.reshape(-1, 1))\n",
        "  Y_train = enc.transform(Y_train.reshape(-1, 1))\n",
        "  Y_val = enc.transform(Y_val.reshape(-1, 1))\n",
        "  Y_test = enc.transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "  return X_train, X_val, X_test, Y_train, Y_val, Y_test\n",
        "\n",
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = dataset_type(dataset = 'fashion_mnist')\n",
        "# print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "# print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "wzdukjGZgZeJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class of FeedForward Neural Network"
      ],
      "metadata": {
        "id": "DXX2kyFig0i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Question_4_Best_Model', entity = 'ed22s009')\n",
        "class FFNN:\n",
        "  def __init__(self, X, Y,\n",
        "               epochs=100, \n",
        "               hidden_layer_count=4,\n",
        "               hidden_layers=[32, 64, 128, 256],\n",
        "               learning_rate=0.001,\n",
        "               batch_size=32,\n",
        "               activation='tanh',\n",
        "               weight_init='random',\n",
        "               loss='mean_squared_error',\n",
        "               weight_decay=0):\n",
        "    \n",
        "    self.params = {\n",
        "      'inputs': X.shape[1],\n",
        "      'outputs': Y.shape[1],\n",
        "      'epochs': epochs,\n",
        "      'hidden_layers': hidden_layer_count,\n",
        "      'network_size': [X.shape[1]] + hidden_layers +[Y.shape[1]],\n",
        "      'learning_rate': learning_rate,\n",
        "      'batch_size': batch_size,\n",
        "      'weights': {},\n",
        "      'weight_init': weight_init,\n",
        "      'activation_function':activation,\n",
        "      'loss_function': loss,\n",
        "      'lambd': weight_decay\n",
        "    }\n",
        "\n",
        "    self.update(self.params)\n",
        "    np.random.seed(0)\n",
        "\n",
        "  def update(self, params):\n",
        "    for key, value in params.items():\n",
        "      setattr(self, key, value)\n",
        "\n",
        "    self.grad_derivatice={}\n",
        "    self.u_w = {f'{key}{i}': 0 for i in range(1, self.hidden_layers+1) for key in ['vw','vb', 'mb', 'mw']}\n",
        "    self.p_u_w = {f'{key}{i}': 0 for i in range(1, self.hidden_layers+1) for key in ['vw', 'vb', 'mb', 'mw']}\n",
        "\n",
        "    # for creating initial weights\n",
        "    if self.weight_init == 'random':\n",
        "      for i in range(1, self.hidden_layers + 2):\n",
        "          weight_shape = (self.network_size[i - 1], self.network_size[i])\n",
        "          weight_scale = 0.1\n",
        "          np.random.seed(0) # including random seet fpr reproducibilty\n",
        "          self.weights[f'W{i}'] = np.random.normal(scale=weight_scale, size=weight_shape)*0.1\n",
        "          # we are mulliplying ny 0.1 to get less wrights\n",
        "          bias_shape = (1, self.network_size[i])\n",
        "          self.weights[f'B{i}'] = np.zeros(bias_shape)\n",
        "\n",
        "    if self.weight_init == 'Xavier':\n",
        "      for i in range(1, self.hidden_layers + 2):\n",
        "          weight_shape = (self.network_size[i - 1],self.network_size[i])\n",
        "          weight_scale = 0.1\n",
        "          np.random.seed(0)\n",
        "          self.weights[f'W{i}'] = np.random.normal(scale=weight_scale,size=weight_shape)*np.sqrt(1/self.network_size[i-1])\n",
        "          # we are mulliplying ny 0.1 to get less wrights\n",
        "          bias_shape = (1, self.network_size[i])\n",
        "          self.weights[f'B{i}'] = np.zeros(bias_shape)\n",
        "\n",
        "\n",
        "\n",
        "  def forward_activation(self, X):\n",
        "      # Define a dictionary of activation functions and their corresponding lambda functions\n",
        "    activation_functions = {\n",
        "        'sigmoid': lambda x: 1.0 / (1.0 + np.exp(-x)), # sigmoid activation function\n",
        "        'tanh': np.tanh, # hyperbolic tangent activation function\n",
        "        'ReLU': lambda x: np.maximum(0, x) # rectified linear unit (ReLU) activation function\n",
        "    }\n",
        "    # Get the activation function based on the value of `self.activation_function`\n",
        "    activation_function = activation_functions.get(self.activation_function)\n",
        "    # If the activation function is found, apply it to the input matrix `X`\n",
        "    if activation_function:\n",
        "        return activation_function(X)\n",
        "    # If the activation function is not found, raise a ValueError indicating that it is unknown\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown activation function '{self.activation_function}'\")\n",
        "\n",
        "\n",
        "\n",
        "  def grad_activation(self, X):\n",
        "    # Define a dictionary of activation function derivatives and their corresponding lambda functions\n",
        "    activation_gradients = {\n",
        "        'sigmoid': lambda x: x * (1 - x), # derivative of the sigmoid activation function\n",
        "        'tanh': lambda x: 1 - np.square(x), # derivative of the hyperbolic tangent activation function\n",
        "        'ReLU': lambda x: 1.0 * (x > 0) # derivative of the rectified linear unit (ReLU) activation function\n",
        "    }\n",
        "    # Get the derivative of the activation function based on the value of `self.activation_function`\n",
        "    gradient_function = activation_gradients.get(self.activation_function)\n",
        "    # If the derivative function is found, apply it to the input matrix `X`\n",
        "    if gradient_function:\n",
        "        return gradient_function(X)\n",
        "    # If theerivative function is not found, raise a alueError indicating that it is unknown\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown activation function '{self.activation_function}'\")\n",
        "\n",
        "\n",
        "  def softmax(self, X):\n",
        "    exps =np.exp(X - np.max(X, axis=1, keepdims=True)) # to reduce long numbers\n",
        "    return  exps /np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "  def forward_pass(self, X, weights=None):\n",
        "    # X: shape (batch_size, input_dim)\n",
        "    if weights is None:\n",
        "        weights = self.weights\n",
        "\n",
        "    # Initialize dictionaries to store intermediate outputs\n",
        "    self.z = {}\n",
        "    self.h = {}\n",
        "    self.h[0] = X\n",
        "\n",
        "    # Perform forward pass through hidden layers\n",
        "    for i in range(self.hidden_layers):\n",
        "        # Compute weighted sum of inputs and biases\n",
        "        z_i = self.h[i] @ weights[f'W{i+1}']\n",
        "        z_i = z_i + weights[f'B{i+1}']\n",
        "        self.z[i+1] = z_i\n",
        "        # Apply activation function\n",
        "        h_i = self.forward_activation(z_i)\n",
        "        self.h[i+1] = h_i\n",
        "\n",
        "    # Compute final output\n",
        "    z_final = self.h[self.hidden_layers] @ weights[f'W{self.hidden_layers+1}']\n",
        "    z_final = z_final + weights[f'B{self.hidden_layers+1}']\n",
        "    self.z[self.hidden_layers+1] = z_final\n",
        "\n",
        "    # Apply softmax activation functionto final output\n",
        "    h_final = self.softmax(z_final)\n",
        "    self.h[self.hidden_layers+1] = h_final\n",
        "    # Return final output\n",
        "    return h_final\n",
        "\n",
        "  def backprop(self, X, Y, weights=None):\n",
        "    #X(batch_size, input_size)\n",
        "    #Y(batch_size, output_size)\n",
        "    if weights is None:\n",
        "        weights = self.weights\n",
        "    # Perform forward pass\n",
        "    self.forward_pass(X, weights)\n",
        "    # Initialize dictionary to storegradients\n",
        "    self.grad_derivatice = {}\n",
        "    total_layers = self.hidden_layers + 1\n",
        "    # Calculate gradients for output layer based on the selected loss function\n",
        "    if self.loss_function == 'cross_entropy':\n",
        "        self.grad_derivatice[f'dA{total_layers}'] = (self.h[total_layers] -Y)\n",
        "    elif self.loss_function == 'mean_squared_error':\n",
        "        self.grad_derivatice[f'dA{total_layers}'] = (1/X.shape[0]) * 2 * (self.h[total_layers] - Y)\n",
        "\n",
        "    # Loop through hidden layers in reverse order andalculate gradients\n",
        "    for k in range(total_layers, 0, -1):\n",
        "        # Define keys for weightsiases, and gradients\n",
        "        w_key, b_key, dw_key, db_key, da_key = [f'{key}{k}' for key in ['W', 'B', 'dW', 'dB', 'dA']]\n",
        "        # Calculate gradients for weights\n",
        "        dw = np.matmul(self.h[k-1].T, self.grad_derivatice[da_key])\n",
        "        dw_reg = dw+ self.lambd *weights[w_key]\n",
        "        self.grad_derivatice[dw_key] = dw_reg\n",
        "        # Calculate gradients forbiases\n",
        "        db = np.sum(self.grad_derivatice[da_key], axis=0).reshape(1, -1)\n",
        "        db_reg = db + self.lambd * weights[b_key]\n",
        "        self.grad_derivatice[db_key] = db_reg\n",
        "        # Calculategradient for previous layer's output\n",
        "        dH = np.matmul(self.grad_derivatice[da_key], weights[w_key].T)\n",
        "        self.grad_derivatice[f'dH{k-1}'] = dH\n",
        "        # Calculate gradient for previous layer'sactivation\n",
        "        dA = np.multiply(dH, self.grad_activation(self.h[k-1]))\n",
        "        self.grad_derivatice[f'dA{k-1}'] =dA\n",
        "        # Calculate gradient for regularizationterm\n",
        "        reg_grad = self.lambd *weights[w_key]\n",
        "        self.grad_derivatice[f'dW_reg{k}'] = reg_grad\n",
        "    # Add regularization gradient to gradients for weights\n",
        "    for k in range(1, total_layers+1):\n",
        "        dw_key, dw_reg_key = [f'{key}{k}' for key in ['dW', 'dW_reg']]\n",
        "        self.grad_derivatice[dw_key] += self.grad_derivatice[dw_reg_key]\n",
        "        # dw_key, dw_reg_key = [f'{key}{k}' for key in ['dW']]\n",
        "        # self.grad_derivatice[dw_key] = self.grad_derivatice[dw_reg_key]\n",
        "    # Return gradient for previous layer's output\n",
        "    return self.grad_derivatice[f'dH{k-1}']\n",
        "\n",
        "\n",
        "  def fit(self, X, Y, X_val, Y_val,algo= 'GD',a = 10, eps=1e-8, beta=0.9, beta1=0.9, beta2=0.9, gamma=0.9, show_loss = False):\n",
        "    #X(batch_size, input_size)\n",
        "    #Y(batch_size, output_size)\n",
        "    if show_loss:\n",
        "      los = []\n",
        "      accuracy = []\n",
        "    for num_epoch in tqdm(range(1, self.epochs+1), unit='epoch'):\n",
        "      m = X.shape[0]\n",
        "      \n",
        "      if algo == 'sgd':\n",
        "          # Loop over the number of samples\n",
        "          for i in range(m):\n",
        "              # Select a random sample\n",
        "              rand_idx = np.random.randint(m)\n",
        "              x_i = X[rand_idx:rand_idx+1]\n",
        "              y_i = Y[rand_idx:rand_idx+1]\n",
        "\n",
        "              # Perform backpropagation on the sample\n",
        "              self.backprop(x_i, y_i)\n",
        "\n",
        "              # Loop over the hidden layers\n",
        "              for j in range(1, self.hidden_layers+1):\n",
        "                  # Get the keys for the weights, biases, and gradients\n",
        "                  w_key, b_key, dw_key, db_key = [f'{key}{j}' for key in ['W', 'B', 'dW', 'dB']]\n",
        "                  # w_key(prev_layer_output_dim,layer_output_dim)\n",
        "                  # b_key1,layer_output_dim)\n",
        "                  # dw_key(prev_layer_output_dim,layer_output_dim)\n",
        "                  # db_key(1,layer_output_dim)\n",
        "\n",
        "                  # Update the weights and biases using the gradients\n",
        "                  self.weights[w_key] -= self.learning_rate * self.grad_derivatice[dw_key]\n",
        "                  self.weights[b_key] -= self.learning_rate * self.grad_derivatice[db_key]\n",
        "                  # self.weights[w_key] -= self.learning_rate * self.grad_derivatice[dw_key]/m\n",
        "                  # self.weights[b_key] -= self.learning_rate * self.grad_derivatice[db_key]/m\n",
        "\n",
        "          # Log the results for this epoch\n",
        "          self.wandlog(num_epoch, X, Y, X_val, Y_val)\n",
        "\n",
        "      \n",
        "      elif algo == 'momentum':\n",
        "          num_examples = X.shape[0]\n",
        "          num_batches = num_examples // self.batch_size\n",
        "          gamma = 0.9  \n",
        "          for batch in range(num_batches + 1):\n",
        "              start_index = batch * self.batch_size\n",
        "              end_index = min((batch + 1) * self.batch_size, num_examples)\n",
        "              X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "              self.backprop(X_batch, Y_batch)\n",
        "\n",
        "              for i in range(1, self.hidden_layers + 1):\n",
        "                  w_key, b_key, vw_key, vb_key, dw_key, db_key = [f'{key}{i}' for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                  # w_key(prev_layer_output_dim,layer_output_dim)\n",
        "                  # b_key1,layer_output_dim)\n",
        "                  # dw_key(prev_layer_output_dim,layer_output_dim)\n",
        "                  # db_key(1,layer_output_dim)\n",
        "\n",
        "                  self.u_w[vw_key] = gamma * self.u_w[vw_key] + self.learning_rate * self.grad_derivatice[dw_key]\n",
        "                  self.u_w[vb_key] = gamma * self.u_w[vb_key] + self.learning_rate * self.grad_derivatice[db_key]\n",
        "                  grad_dw = self.grad_derivatice[dw_key] + gamma * self.u_w[vw_key]\n",
        "                  grad_db = self.grad_derivatice[db_key] + gamma * self.u_w[vb_key]\n",
        "\n",
        "                  # Update weights and biases\n",
        "                  self.weights[w_key] -= self.learning_rate * grad_dw\n",
        "                  self.weights[b_key] -= self.learning_rate * grad_db\n",
        "\n",
        "              # Log the loss and accuracy after every N steps\n",
        "          self.wandlog(num_epoch, X, Y, X_val, Y_val)\n",
        "\n",
        "\n",
        "      \n",
        "      elif algo == 'rmsprop':\n",
        "          num_examples =X.shape[0]\n",
        "          num_batches = num_examples//self.batch_size\n",
        "\n",
        "          for batch in range(num_batches + 1):\n",
        "              start_index = batch *self.batch_size\n",
        "              end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "              X_batch, Y_batch = X[start_index:end_index],Y[start_index:end_index]\n",
        "              # X_batch, Y_batch = X[start_index:end_index],Y[start_index:0]\n",
        "              self.backprop(X_batch, Y_batch)\n",
        "\n",
        "              for i in range(1, self.hidden_layers+1):\n",
        "                  w_key, b_key, vw_key, vb_key, dw_key, db_key = [f'{key}{i}' for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                  # The shape of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "                  # The shape of the bias matrix for this layer (1, layer_output_dim)\n",
        "                  # The shape of the gradient of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "                  # The shape of the gradient of the bias matrix for this layer (1, layer_output_dim)\n",
        "                  prev_layer_output_dim = self.weights[f'{w_key}'].shape[0]\n",
        "                  layer_output_dim = self.weights[f'{w_key}'].shape[1]\n",
        "\n",
        "                  # Compute gradients for this layer\n",
        "\n",
        "                  dW, dB = self.grad_derivatice[dw_key],self.grad_derivatice[db_key]\n",
        "                  dw_squared =np.square(dW)\n",
        "                  db_squared= np.square(dB)\n",
        "\n",
        "                  # self.u_w[vw_key] = beta *self.u_w[vw_key] + (1 - beta)\n",
        "                  # self.u_w[vb_key] =beta* self.u_w[vb_key]+ (1 - beta)\n",
        "\n",
        "                  # Update the exponentially weighted averages of the squared gradients\n",
        "                  self.u_w[vw_key] =beta*self.u_w[vw_key] +(1 -beta) *dw_squared\n",
        "                  self.u_w[vb_key] =beta* self.u_w[vb_key]+(1- beta)* db_squared\n",
        "\n",
        "                  # Compute the RMSProp update for the weights and biases\n",
        "                  dw_rms = np.sqrt(self.u_w[vw_key] + 1e-8)\n",
        "                  db_rms = np.sqrt(self.u_w[vb_key] + 1e-8)\n",
        "                  # Updating weights\n",
        "                  dw_update = (self.learning_rate / dw_rms) * dW\n",
        "                  db_update = (self.learning_rate / db_rms) * dB\n",
        "\n",
        "                  # Update the weights and biases\n",
        "                  self.weights[w_key] -= dw_update\n",
        "                  self.weights[b_key] -= db_update\n",
        "\n",
        "          self.wandlog(num_epoch, X, Y, X_val, Y_val)\n",
        "      \n",
        "      elif algo == 'adam':\n",
        "          num_examples = X.shape[0]\n",
        "          num_batches = num_examples //self.batch_size\n",
        "\n",
        "          for batch in range(num_batches + 1):\n",
        "              start_index = batch *self.batch_size\n",
        "              end_index = min((batch+1)*self.batch_size,num_examples)\n",
        "              X_batch, Y_batch =X[start_index:end_index],Y[start_index:end_index]\n",
        "\n",
        "              self.backprop(X_batch, Y_batch)\n",
        "\n",
        "              for i in range(1, self.hidden_layers + 1):\n",
        "                  w_key, b_key, vw_key, vb_key, mw_key, mb_key = [f'{key}{i}' for key in ['W', 'B', 'vw', 'vb', 'mw', 'mb']]\n",
        "                  # The shape of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "                  # The shape of the bias matrix for this layer (1, layer_output_dim)\n",
        "                  # The shape of the gradient of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "                  # The shape of the gradient of the bias matrix for this layer (1, layer_output_dim)\n",
        "                  dw_key, db_key= [f'{key}{i}' for key in ['dW', 'dB']]\n",
        "                  # Compute gradients for the current layer\n",
        "                  dW = self.grad_derivatice[dw_key]\n",
        "                  dB = self.grad_derivatice[db_key]\n",
        "\n",
        "                  # Update moving av erages for the current layer's weights\n",
        "                  self.u_w[mw_key] = beta1* self.u_w[mw_key] +(1 -beta1) * dW\n",
        "                  self.u_w[vw_key] =beta2 *self.u_w[vw_key]+ (1- beta2) *(dW ** 2)\n",
        "\n",
        "                  # Compute bias-corrected moving averages for the current layer's weights\n",
        "                  mw_hat = self.u_w[mw_key] / (1 -np.power(beta1, batch + 1))\n",
        "                  vw_hat = self.u_w[vw_key]/ (1- np.power(beta2, batch + 1))\n",
        "\n",
        "                  # Update the current layer's weights using the bias-corrected moving averages\n",
        "                  self.weights[w_key] -= (self.learning_rate / np.sqrt(vw_hat + eps)) * mw_hat\n",
        "\n",
        "                  # Update moving averages for the current layer's biases\n",
        "                  self.u_w[mb_key] = beta1 * self.u_w[mb_key] + (1 - beta1) * dB\n",
        "                  self.u_w[vb_key] = beta2 * self.u_w[vb_key] + (1 - beta2) * (dB ** 2)\n",
        "                  # self.u_w[mb_key] = beta1 * self.u_w[mb_key] + (1 - beta1) \n",
        "                  # self.u_w[vb_key] = beta2 * self.u_w[vb_key] + (1 - beta2) \n",
        "\n",
        "                  # Compute bias-correctedmoving averages for the current layer's biases\n",
        "                  mb_hat =self.u_w[mb_key] /(1- np.power(beta1, batch + 1))\n",
        "                  vb_hat = self.u_w[vb_key]/ (1 -np.power(beta2,batch + 1))\n",
        "\n",
        "                  # Update the current layer's biases using the bias-corrected moving verages\n",
        "                  self.weights[b_key]-=(self.learning_rate /np.sqrt(vb_hat + eps)) *mb_hat\n",
        "\n",
        "          # Log epoch information\n",
        "          self.wandlog(num_epoch,X,Y, X_val,Y_val)\n",
        "\n",
        "          \n",
        "      elif algo == 'nag':\n",
        "        # Calculate number of examples and batches\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        # Initialize temporary weight variables for each layer\n",
        "        temp_weights = {}\n",
        "        for i in range(1, self.hidden_layers+2):\n",
        "          w_key, b_key = [f'{key}{i}' for key in ['W', 'B']]\n",
        "\n",
        "          temp_weights[w_key] = np.zeros_like(self.weights[w_key])\n",
        "\n",
        "          temp_weights[b_key] = np.zeros_like(self.weights[b_key])\n",
        "\n",
        "        # Iterate over each batch of data\n",
        "        for batch in range(num_batches + 1):\n",
        "            # Set start and end indices for the current batch\n",
        "            start_index = batch *self.batch_size\n",
        "\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "\n",
        "            # Select batch of data\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            # Update weights using Nesterov accelerated gradient descent\n",
        "            for i in range(1,self.hidden_layers+1):\n",
        "                # Set variable names for weights, biases, velocity for current layer\n",
        "                w_key, b_key, vw_key, vb_key,dw_key, db_key = [f'{key}{i}' for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                # The shape of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "                 # The shape of the bias matrix for this layer (1, layer_output_dim)\n",
        "                   # The shape of the gradient of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "                 # The shape of the gradient of the bias matrix for this layer (1, layer_output_dim)\n",
        "                # Update velocity using Nesterov accelerated gradient descent\n",
        "                self.u_w[vw_key]=gamma*self.p_u_w[vw_key]\n",
        "\n",
        "                self.u_w[vb_key]=gamma*self.p_u_w[vb_key]\n",
        "\n",
        "                temp_weights[w_key]=self.weights[w_key]-self.u_w[vw_key]\n",
        "\n",
        "\n",
        "                temp_weights[b_key]=self.weights[b_key]-self.u_w[vb_key]\n",
        "            \n",
        "            # Perform backpropagation to calculate gradients\n",
        "            self.backprop(X_batch,Y_batch,temp_weights)\n",
        "\n",
        "            # Update weights for each layer using Nesterov accelerated gradient descent\n",
        "            for i in range(1,self.hidden_layers+1):\n",
        "                # Set variable names for weights, biases, velocity for current layer\n",
        "                w_key, b_key, vw_key, vb_key,dw_key, db_key = [f'{key}{i}' for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                # Update velocity using Nesterov accelerated gradient descent\n",
        "                self.u_w[vw_key] = gamma *self.u_w[vw_key] + self.learning_rate * (self.grad_derivatice[dw_key])\n",
        "                self.u_w[vb_key] = gamma *self.u_w[vb_key] + self.learning_rate * (self.grad_derivatice[db_key])\n",
        "                # Update weights using velocity and learning rate\n",
        "                self.weights[w_key] -= self.learning_rate * (self.u_w[vw_key]/m)\n",
        "                self.weights[b_key] -= self.learning_rate * (self.u_w[vb_key]/m) \n",
        "\n",
        "            # Set the previous velocity to the current velocity\n",
        "            self.p_u_w=self.u_w\n",
        "\n",
        "        # Call wandlog method to log training and validation loss and accuracy\n",
        "        self.wandlog(num_epoch, X, Y,X_val, Y_val)\n",
        "\n",
        "\n",
        "\n",
        "      elif algo == 'nadam':\n",
        "\n",
        "        num_examples =X.shape[0]   # For batching\n",
        "        num_batches =num_examples//self.batch_size  # For batches in iterations\n",
        "\n",
        "        num_updates = 0 # For loops\n",
        "\n",
        "        # Loop through each layer in the network\n",
        "        for i in range(1, self.hidden_layers + 1):\n",
        "            # Get the keys for the weights, biases, velocity, momentum, and infinite norm buffers for this layer\n",
        "            w_key, b_key, vw_key, vb_key, mw_key, mb_key = [f'{key}{i}' for key in ['W', 'B', 'vw', 'vb', 'mw', 'mb']]\n",
        "            # The shape of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "            # The shape of the bias matrix for this layer (1, layer_output_dim)\n",
        "            # The shape of the gradient of the weight matrix for this layer (prev_layer_output_dim, layer_output_dim)\n",
        "            # The shape of the gradient of the bias matrix for this layer (1, layer_output_dim)\n",
        "\n",
        "            dw_key,db_key, mw_i_key,mb_i_key =[f'{key}{i}' for key in ['dW', 'dB', 'mw_inf', 'mb_inf']]\n",
        "\n",
        "            # Loop through each batch of examples\n",
        "            for batch in range(num_batches + 1):\n",
        "                start_index =batch * self.batch_size\n",
        "                end_index =min((batch + 1) * self.batch_size, num_examples)\n",
        "                X_batch,Y_batch = X[start_index:end_index],Y[start_index:end_index]\n",
        "                # X_batch,Y_batch = X[start_index:end_index, start_index:end_index]\n",
        "\n",
        "                # Perform backpropagation on the current batch\n",
        "                self.backprop(X_batch, Y_batch)\n",
        "\n",
        "                num_updates += 1\n",
        "\n",
        "                # Initialize the velocity, momentum, and infinite norm buffers for this layer if they haven't been already\n",
        "                self.u_w.setdefault(mw_i_key,0)  # shape: (prev_layer_output_dim, layer_output_dim)\n",
        "                # Update the velocity buffer for the weights\n",
        "                self.u_w[mw_key] =beta1 *self.u_w[mw_key] +(1 - beta1)*(self.grad_derivatice[dw_key])\n",
        "                # Update the velocity buffer for the squared gradients of the weights\n",
        "                self.u_w[vw_key] =beta2*self.u_w[vw_key] +(1 - beta2)*((self.grad_derivatice[dw_key]) ** 2)\n",
        "                # Comput thias-correced velocity and square gradient velocity for the weights\n",
        "                mw_hat = self.u_w[mw_key] /(1 - np.power(beta1,num_updates))\n",
        "                vw_hat = self.u_w[vw_key] /(1 - np.power(beta2,num_updates))\n",
        "                # Compute the infinte norm buffer for he weights\n",
        "                mw_inf = beta1 * self.u_w[mw_i_key] + (1 - beta1) * np.abs(self.grad_derivatice[dw_key])\n",
        "                # Compute the bias-correctedinfinite norm buffer for the weights\n",
        "                mw_inf_hat = mw_inf/(1 -np.power(beta1, num_updates))\n",
        "                # Update the weights usingthe NAdam update rule\n",
        "                self.weights[w_key] -=(self.learning_rate /np.sqrt(vw_hat + eps)) *((beta1 *mw_hat) +((1 -beta1) *self.grad_derivatice[dw_key]))/ (1 -np.power(beta2,num_updates)) + self.learning_rate * eps * np.sqrt(1 - np.power(beta2, num_updates)) * mw_inf_hat\n",
        "                # self.weights[mb_key] = beta1* self.u_w[mb_key] + (1 - beta1) *(self.grad_derivatice[db_key])\n",
        "                # self.weights[vb_key] = beta2 *self.u_w[vb_key] + (1 - beta2)* ((self.grad_derivatice[db_key]) ** 2)\n",
        "\n",
        "                # Set default value of mb_i_key to 0 in u_w dictionary\n",
        "                self.u_w.setdefault(mb_i_key, 0)\n",
        "\n",
        "                # Update u_w dictionaryfor mb_keyand vb_keyusing Adam optimizer\n",
        "                self.u_w[mb_key] = beta1* self.u_w[mb_key] + (1 - beta1) *(self.grad_derivatice[db_key])\n",
        "                self.u_w[vb_key] = beta2 *self.u_w[vb_key] + (1 - beta2)* ((self.grad_derivatice[db_key]) ** 2)\n",
        "\n",
        "                # Compute bias-correctedestimates for mb_keyand vb_key\n",
        "                mb_hat = self.u_w[mb_key] / (1 - np.power(beta1, num_updates))\n",
        "                vb_hat = self.u_w[vb_key] / (1 - np.power(beta2, num_updates))\n",
        "\n",
        "                # Compute exponentiallyweighted infinity normof gradient for mb_i_key\n",
        "                mb_inf =beta1 *self.u_w[mb_i_key] + (1 - beta1) *np.abs(self.grad_derivatice[db_key])\n",
        "\n",
        "                # Compute bias-corrected estimate for mb_inf\n",
        "                mb_inf_hat =mb_inf/ (1 -np.power(beta1, num_updates))\n",
        "\n",
        "                # Update weights using Adam optimizer and the computed estimates\n",
        "                self.weights[b_key]-=(self.learning_rate /np.sqrt(vb_hat + eps)) *((beta1 * mb_hat) +((1 - beta1) *self.grad_derivatice[db_key])) /(1 - np.power(beta2, num_updates))+ self.learning_rate * eps * np.sqrt(1 - np.power(beta2, num_updates)) * mb_inf\n",
        "\n",
        "        # Log and track the training and validation loss\n",
        "        self.wandlog(num_epoch,X,Y,X_val, Y_val)\n",
        "\n",
        "            \n",
        "      if show_loss:\n",
        "          # Calculate the performance on the validation set and append to the lists\n",
        "        loss, acc = self.performance(X_val, Y_val)\n",
        "        los.append(loss)\n",
        "        accuracy.append(acc)\n",
        "\n",
        "\n",
        "# For showing loss\n",
        "    if show_loss:\n",
        "\n",
        "        # Find the index of maximum validation accuracy achieved during training\n",
        "        max_acc_index = np.argmax(accuracy)\n",
        "        # min_los_index = np.argmin(los)\n",
        "        # Plot the loss and accuracy curves, with markers indicating the position of the maximum validation accuracy\n",
        "        plt.plot(los, label='Loss')\n",
        "        plt.plot(accuracy, label='Accuracy')\n",
        "        # plt.plot(max_acc_index,los[min_los_index], marker='o',color='red')\n",
        "        # plt.plot(min_los_index,accuracy[min_los_index], marker='o',color='green')\n",
        "        plt.plot(max_acc_index,los[max_acc_index], marker='o',color='red')\n",
        "        plt.plot(max_acc_index,accuracy[max_acc_index], marker='o',color='green')\n",
        "\n",
        "        # Annotate the plot with the loss value and accuracy value achieved at the maximum validation accuracy point\n",
        "        plt.text(max_acc_index,los[max_acc_index],f'loss @ Max val acc:( {los[max_acc_index]:.4f})', va='top')\n",
        "        plt.text(max_acc_index, accuracy[max_acc_index],f'Max Val acc: ({accuracy[max_acc_index]:.4f})',va='bottom')\n",
        "\n",
        "        # Set the y-axis limits for the plot\n",
        "        plt.ylim([min(los + accuracy)-0.1, max(los + accuracy) + 0.1])\n",
        "            #  plt.ylim([min(los + accuracy), max(los + accuracy) ])\n",
        "        # Add a title and axis labels to the plot, and display it\n",
        "        plt.title('Val Loss and val Accuracy with {}'.format(self.loss_function))\n",
        "\n",
        "        plt.xlabel('Epochs')\n",
        "\n",
        "        plt.ylabel('Loss / Accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "      '''\n",
        "      Given input data X, predict the output using the trained neural network model.\n",
        "\n",
        "      Args:\n",
        "      - X: Input data of shape (num_samples, input_size)\n",
        "\n",
        "      Returns:\n",
        "      - Y_pred: Predicted output of shape (num_samples, output_size)\n",
        "      '''\n",
        "      Y_pred = (self.forward_pass(X))\n",
        "      return np.array(Y_pred).squeeze()\n",
        "\n",
        "\n",
        "  def accuracy_score(self, X, Y):\n",
        "      '''\n",
        "      Calculate the accuracy score of the trained neural network model on the given input data and output labels.\n",
        "\n",
        "      Args:\n",
        "      - X: Input data of shape (num_samples, input_size)\n",
        "      - Y: Output labels of shape (num_samples, output_size)\n",
        "\n",
        "      Returns:\n",
        "      - accuracy: Accuracy score of the model\n",
        "      '''\n",
        "      Y_true = np.argmax(Y, axis=1).reshape(-1, 1)\n",
        "      pred_labels = np.argmax(self.predict(X), axis=1).reshape(-1,1)\n",
        "      return np.sum(pred_labels == Y_true) / len(Y)\n",
        "\n",
        "\n",
        "  def Loss(self, X, Y):\n",
        "  \n",
        "      # Calculate the loss of the trained neural network model on the given input data and output labels.\n",
        "\n",
        "      # Args:\n",
        "      # - X: Input data of shape (num_samples, input_size)\n",
        "      # - Y: Output labels of shape (num_samples, output_size)\n",
        "\n",
        "      Y_pred = self.predict(X)\n",
        "      if self.loss_function =='cross_entropy':\n",
        "          loss = -np.mean(Y * np.log(Y_pred + 1e-8))\n",
        "      elif self.loss_function== 'mean_squared_error':\n",
        "\n",
        "          loss =np.mean((Y - Y_pred)**2)/2\n",
        "\n",
        "      else:\n",
        "          raise ValueError('Invalid loss function')\n",
        "          \n",
        "      # Returns:\n",
        "      # - loss: Loss of the model\n",
        "      return loss\n",
        "\n",
        "\n",
        "  def performance(self, X_test, Y_test):\n",
        "\n",
        "      # Calculate the performance of the trained neural network model on the given test data and output labels.\n",
        "\n",
        "      # Args:\n",
        "      # - X_test: Test data of shape (num_samples, input_size)\n",
        "      # - Y_test: Output labels of shape (num_samples, output_size)\n",
        "\n",
        "      loss = self.Loss(X_test,Y_test)\n",
        "\n",
        "      accuracy =self.accuracy_score(X_test, Y_test)\n",
        "      # Returns:\n",
        "      # - loss: Loss of the model on the test data\n",
        "      # - accuracy: Accuracy score of the model on the test data\n",
        "      return loss, accuracy\n",
        "\n",
        "\n",
        "# code for confusion matrix\n",
        "  def confusion_matrix(self, X, Y):\n",
        "      \n",
        "# Get the actual labels by takinthe index of the maximum value in Y\n",
        "    a = np.argmax(Y,axis=1)\n",
        "    \n",
        "   # Get the predicted labels by taking the index of the maximumvalue in the output of frward_pss method\n",
        "    p = np.argmax(self.forward_pass(X), axis=1)\n",
        "    \n",
        "  # Get all the avaiable classes by combining actual and prected labels and then finding unue classes\n",
        "    ap = np.concatenate((a, p))\n",
        "    c = np.unique(ap)\n",
        "    \n",
        "  # Create an empty confusion matrix with dimnsions equal to numberof available classes\n",
        "    cm = np.zeros((len(c),len(c)),dtype=int)\n",
        "    \n",
        "  # Fill the confusion marix with thecounts of actual and predicted lels for each class\n",
        "    for i, actual in enumerate(c):\n",
        "\n",
        "\n",
        "        for j, predicted in enumerate(c):\n",
        "\n",
        "            count = np.where((a == actual) & (p == predicted))[0].shape[0]\n",
        "\n",
        "            cm[i,j] = count\n",
        "    # ap = np.concatenate((a, p))\n",
        "    # c = np.unique(ap)\n",
        "    # Log the confusion matrix as an interacte plot to Weights and Biases\n",
        "    wandb.log({'confusion_matrix': wandb.plot.confusion_matrix(\n",
        "        probs=None,\n",
        "        y_true=a,\n",
        "\n",
        "        preds=p,\n",
        "        class_names=list(c),\n",
        "\n",
        "        title='Confusion Matrix'\n",
        "    )})\n",
        "    \n",
        "    # Return the confusion matrix\n",
        "    return cm\n",
        "\n",
        "  def confo_matrixplot(self, confusion_matrix, title='Confusion Matrix', cmap='PuBu'):\n",
        "\n",
        "    # Convert confusion matrix to a numpy array\n",
        "\n",
        "    confusion_matrix =np.array(confusion_matrix)\n",
        "    # Normalize thconfusion matrix by dividieach row by its sum\n",
        "\n",
        "    confusion_matrix= confusion_matrix / np.sum(confusion_matrix,axis=1,keepdims=True)\n",
        "\n",
        "    # Plot thenormalized confusionmatrix as a heatmap using the specified color map\n",
        "\n",
        "    # plt.matshow(confusion_matrix)\n",
        "\n",
        "    # plt.colorbar()\n",
        "\n",
        "    # tick_marks =np.arange((confusion_matrix))\n",
        "\n",
        "    plt.matshow(confusion_matrix,cmap=cmap)\n",
        "\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks =np.arange(len(confusion_matrix))\n",
        "\n",
        "    plt.xticks(tick_marks)\n",
        "    plt.yticks(tick_marks)\n",
        "    # Add labels for the x and y axes\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    # Add a title for the plot\n",
        "    plt.title(title)\n",
        "    # Display the plot\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def wandlog(self,num_epoch,X,Y,X_val,Y_val):\n",
        "\n",
        "      # Calculate accuracy and loss on training data\n",
        "\n",
        "      accuracy = self.accuracy_score(X, Y)\n",
        "\n",
        "      loss_train = self.Loss(X, Y)\n",
        "      \n",
        "      # Calculate accuracy andloss on validation dat\n",
        "      \n",
        "      loss_valid= self.Loss(X_val, Y_val)\n",
        "      val_accuracy= self.accuracy_score(X_val, Y_val)\n",
        "      \n",
        "      # Log themetrics usingwandb for tracking performance\n",
        "\n",
        "      wandb.log({\n",
        "          'epoch': num_epoch,           \n",
        "          'loss': loss_train,\n",
        "\n",
        "          'accuracy': accuracy,\n",
        "          'val_loss': loss_valid,\n",
        "\n",
        "          'val_accuracy': val_accuracy\n",
        "      })\n",
        "      \n",
        "      # Print themetrics every1 epoch for givrn modle run\n",
        "      if num_epoch % 1 ==0:\n",
        "          # Calculate accuracy and loss ontraining data on given epoch\n",
        "\n",
        "          accuracy= self.accuracy_score(X, Y)\n",
        "\n",
        "          loss_train =self.Loss(X, Y)\n",
        "          \n",
        "          # Calculate accuracy and loss on validation data in givenepoch\n",
        "          loss_valid =self.Loss(X_val, Y_val)\n",
        "\n",
        "          val_accuracy= self.accuracy_score(X_val, Y_val)\n",
        "          \n",
        "          # Store the metrics of performance in  inside  a dictionary\n",
        "          \n",
        "          library = {\n",
        "              'epoch': num_epoch,           \n",
        "              'loss': loss_train,\n",
        "\n",
        "              'accuracy': accuracy,\n",
        "              'val_loss': loss_valid,\n",
        "              'val_accuracy': val_accuracy\n",
        "\n",
        "\n",
        "          }\n",
        "\n",
        "          # Print the metrics of perfromnce\n",
        "          print('Epoch: {}, Train Loss: {}, Train Accuracy: {}, Val Loss: {}, Val Accuracy: {}'.format(\n",
        "              library['epoch'], library['loss'], library['accuracy'], library['val_loss'], library['val_accuracy']))\n",
        "          \n",
        "          # Checkif the last epoch has beenreached and print a success message\n",
        "          if num_epoch ==self.epochs:\n",
        "              print('Model trained successfully !')\n",
        "# !python train.py -wp myproject -we ed22s009 -d fashion_mnist -e 20 -b 128 -lr 0.001 -nhl 3 -sz 256 -a tanh -w_i Xavier -w_d 0 -o nadam -l cross_entropy\n",
        "# Model running for good accuracy              \n",
        "# model = FFNN(X_train, Y_train,\n",
        "#                   epochs = 19, \n",
        "#                   hidden_layer_count = 3,\n",
        "#                   hidden_layers =  [256, 256, 256],\n",
        "#                   learning_rate = 0.001,\n",
        "#                   batch_size = 128,\n",
        "#                   activation='tanh',\n",
        "#                   weight_init='Xavier',\n",
        "#                   loss = 'cross_entropy',\n",
        "#                   weight_decay = 0)\n",
        "# model.fit(X_train, Y_train, X_val, Y_val,algo= 'nadam', a = 1, show_loss = True) \n",
        "# confusion_matrix = model.confusion_matrix(X_test, Y_test)\n",
        "# model.confo_matrixplot(confusion_matrix)"
      ],
      "metadata": {
        "id": "roqXcqcDgrri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70f331a728b24d349ea2c02f4b364edb",
            "847d9cca13a144bdbbef2a11826f06f9",
            "9ed905f8a7fd40a6941d716cfd54c392",
            "7652a756a0b947b4b38c17103a84a06b",
            "a8d5313c50fe47808d263436334e2620",
            "1e3ec0c241c54c3092952f2361990cdb",
            "9a44b519136d4b57ad1af041ee1625d9",
            "7da444e86e0a4a5db1db32e32d036b8b",
            "54902b545bbc4fba888c9ae3972cbffc",
            "bd0a438292c94757839f84405d243c1f",
            "c8d832bc4c6445448d31924fe2e2faa6",
            "a72db58376a542d691c8732d7cd644d4",
            "68e7ea312ea245fc9e8ad0d857a973aa",
            "8045b97320f94de89589b77980eaf63e",
            "8eac1188d32b45ed80e3ccec2708e739",
            "f68e70d0e0ae403bae2f30a52bd3d111",
            "5cbf9e346aee4aa795cce5bbfd93f64b",
            "6871900a4b0f458e8d112cf15ba9b942",
            "b1699aeb55e74ef594ae87e22d45a91a"
          ]
        },
        "outputId": "798e37da-33d9-4ff4-d82b-097612e94e5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:docx469o) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.023 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.043985…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70f331a728b24d349ea2c02f4b364edb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▂▂▂▂▄▄▄▄▄▁▇▇▇▇▄▁▂▄▄▄▂▂▂▂▄▄▄▇▆▁███▄▄▃▂▄▄▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▁▁▁▁▁██████▁▁▁▁▁▇▇▇███▁▁▁▁▁██▇▇▇█▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▂▂▂▄▄▄▄▄▁▇▇▇▇▄▁▂▄▄▄▂▂▂▂▄▄▄▇▆▁███▄▄▃▂▄▃▃</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁██████▁▁▁▁▁▇▇▇███▁▁▁▁▁██▇▇▇█▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.24128</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.0415</td></tr><tr><td>val_accuracy</td><td>0.2355</td></tr><tr><td>val_loss</td><td>0.04155</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-serenity-957</strong> at: <a href='https://wandb.ai/ed22s009/Question_4_Best_Model/runs/docx469o' target=\"_blank\">https://wandb.ai/ed22s009/Question_4_Best_Model/runs/docx469o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_053627-docx469o/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:docx469o). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_054901-kou8q0ma</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed22s009/Question_4_Best_Model/runs/kou8q0ma' target=\"_blank\">fluent-deluge-958</a></strong> to <a href='https://wandb.ai/ed22s009/Question_4_Best_Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed22s009/Question_4_Best_Model' target=\"_blank\">https://wandb.ai/ed22s009/Question_4_Best_Model</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed22s009/Question_4_Best_Model/runs/kou8q0ma' target=\"_blank\">https://wandb.ai/ed22s009/Question_4_Best_Model/runs/kou8q0ma</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/19 [00:00<?, ?epoch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54902b545bbc4fba888c9ae3972cbffc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.14375178893550167, Train Accuracy: 0.816462962962963, Val Loss: 0.14406309985437274, Val Accuracy: 0.814\n",
            "Epoch: 2, Train Loss: 0.13871085786611245, Train Accuracy: 0.8629629629629629, Val Loss: 0.13915129526178374, Val Accuracy: 0.8578333333333333\n",
            "Epoch: 3, Train Loss: 0.13685668587977784, Train Accuracy: 0.8811481481481481, Val Loss: 0.13772871296134098, Val Accuracy: 0.8708333333333333\n",
            "Epoch: 4, Train Loss: 0.13576469613845576, Train Accuracy: 0.8903888888888889, Val Loss: 0.13699621039172633, Val Accuracy: 0.8785\n",
            "Epoch: 5, Train Loss: 0.1350157919087659, Train Accuracy: 0.8977407407407407, Val Loss: 0.13652787335775698, Val Accuracy: 0.8828333333333334\n",
            "Epoch: 6, Train Loss: 0.1344300839140759, Train Accuracy: 0.9027592592592593, Val Loss: 0.13622680303411963, Val Accuracy: 0.8868333333333334\n",
            "Epoch: 7, Train Loss: 0.13397770163950254, Train Accuracy: 0.9073703703703704, Val Loss: 0.13603642399392984, Val Accuracy: 0.8878333333333334\n",
            "Epoch: 8, Train Loss: 0.1336243244624736, Train Accuracy: 0.9103148148148148, Val Loss: 0.13595320054160706, Val Accuracy: 0.8888333333333334\n",
            "Epoch: 9, Train Loss: 0.13329475071201852, Train Accuracy: 0.9134074074074074, Val Loss: 0.1357837378193328, Val Accuracy: 0.8888333333333334\n",
            "Epoch: 10, Train Loss: 0.1329903893212549, Train Accuracy: 0.9165925925925926, Val Loss: 0.1356904799148941, Val Accuracy: 0.8901666666666667\n",
            "Epoch: 11, Train Loss: 0.13275087122795823, Train Accuracy: 0.9193518518518519, Val Loss: 0.13561632291182302, Val Accuracy: 0.8925\n",
            "Epoch: 12, Train Loss: 0.13256408817150359, Train Accuracy: 0.9211296296296296, Val Loss: 0.13564235420707332, Val Accuracy: 0.8906666666666667\n",
            "Epoch: 13, Train Loss: 0.13234014110304798, Train Accuracy: 0.9237592592592593, Val Loss: 0.13568920900766335, Val Accuracy: 0.8923333333333333\n",
            "Epoch: 14, Train Loss: 0.13218088634938815, Train Accuracy: 0.9256111111111112, Val Loss: 0.13568723023820745, Val Accuracy: 0.8913333333333333\n",
            "Epoch: 15, Train Loss: 0.13201480669721644, Train Accuracy: 0.9268333333333333, Val Loss: 0.13564379264442453, Val Accuracy: 0.893\n",
            "Epoch: 16, Train Loss: 0.1318609247376912, Train Accuracy: 0.9292962962962963, Val Loss: 0.13566950489006796, Val Accuracy: 0.8923333333333333\n",
            "Epoch: 17, Train Loss: 0.13170590004414262, Train Accuracy: 0.9306296296296296, Val Loss: 0.1355928358331599, Val Accuracy: 0.8928333333333334\n",
            "Epoch: 18, Train Loss: 0.13157810593861108, Train Accuracy: 0.9318333333333333, Val Loss: 0.13559799780404416, Val Accuracy: 0.8938333333333334\n",
            "Epoch: 19, Train Loss: 0.13146893046959365, Train Accuracy: 0.9321481481481482, Val Loss: 0.13560894345281138, Val Accuracy: 0.8956666666666667\n",
            "Model trained successfully !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rough Work"
      ],
      "metadata": {
        "id": "aMZRi3CQAFql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# init_methods = ['random', 'Xavier']\n",
        "# activation_functions = ['sigmoid', 'tanh', 'ReLU']\n",
        "# algos = ['sgd', 'momentum', 'nag', 'rmsprop', 'adam','nadam']\n",
        "# losses = ['cross_entropy', 'mean_squared_error']\n",
        "# c = 0\n",
        "# d = 0\n",
        "# for init_method in init_methods:\n",
        "#     for activation_function in activation_functions:\n",
        "#         for algo in algos:\n",
        "#           for loss in losses:\n",
        "#             print(init_method,activation_function,algo,loss)\n",
        "\n",
        "#             model = FFNN(X_train, Y_train,\n",
        "#                           epochs = 1, \n",
        "#                           hidden_layer_count = 1,\n",
        "#                           hidden_layers =  [10],\n",
        "#                           learning_rate = 0.0001,\n",
        "#                           batch_size = 32,\n",
        "#                           activation=activation_function,\n",
        "#                           weight_init=init_method,\n",
        "#                           loss = loss,\n",
        "#                           weight_decay = 0.0005)\n",
        "#             model.fit(X_train, Y_train, X_val, Y_val,algo= algo)\n",
        "#             c = c + 1\n",
        "\n",
        "#             print(c)"
      ],
      "metadata": {
        "id": "3j8_-hb8268o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}