{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRojjKbKThVRsfUBw7aRid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d33d21840c9343a0b8ddebbe9b61992e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d656b89b97a438085b935037c4e7887",
              "IPY_MODEL_5b0759f7e9924a7fa0bd1fc8e2c72249",
              "IPY_MODEL_2ed0f08664bb42b794f4f47450200999"
            ],
            "layout": "IPY_MODEL_7f4747de7e1243f296ea898eb42b6201"
          }
        },
        "6d656b89b97a438085b935037c4e7887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11797701a5d74aa385229617d39a782f",
            "placeholder": "​",
            "style": "IPY_MODEL_aaa358deeb6e43459573727d5a72f11b",
            "value": "100%"
          }
        },
        "5b0759f7e9924a7fa0bd1fc8e2c72249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5027f501dd064314a0112b4cf6583cac",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94004f84ed504f579a22d6fbda858233",
            "value": 20
          }
        },
        "2ed0f08664bb42b794f4f47450200999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b65386879c4860b1ee91a0f812ccbb",
            "placeholder": "​",
            "style": "IPY_MODEL_3264396849d042ad943de221afda89c3",
            "value": " 20/20 [1:12:08&lt;00:00, 245.48s/epoch]"
          }
        },
        "7f4747de7e1243f296ea898eb42b6201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11797701a5d74aa385229617d39a782f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa358deeb6e43459573727d5a72f11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5027f501dd064314a0112b4cf6583cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94004f84ed504f579a22d6fbda858233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9b65386879c4860b1ee91a0f812ccbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3264396849d042ad943de221afda89c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnilmn/Assignment_1-CS6910/blob/master/Question_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 3 (24 Marks) Implement the backpropagation algorithm with support for the following optimisation functions\n",
        "            sgd\n",
        "            momentum based gradient descent\n",
        "            nesterov accelerated gradient descent\n",
        "            rmsprop\n",
        "            adam\n",
        "            nadam\n",
        "\n",
        "(12 marks for the backpropagation framework and 2 marks for each of the optimisation algorithms above)\n",
        "\n",
        "We will check the code for implementation and ease of use (e.g., how easy it is to add a new optimisation algorithm such as Eve). Note that the code should be flexible enough to work with different batch sizes."
      ],
      "metadata": {
        "id": "3kVFZwNkEA7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries "
      ],
      "metadata": {
        "id": "_dP0oEKrgmQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CZcFz8GygBp5"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist, mnist\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "W-FlxB4-gnqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotEncoder_from_scratch:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.categories = None\n",
        "    def fit(self, X):\n",
        "        self.categories =[]\n",
        "        for i in range(X.shape[1]):\n",
        "            feature_categories =list(set(X[:, i]))\n",
        "            self.categories.append(feature_categories)\n",
        "            \n",
        "    def transform(self, X):\n",
        "        one_hot_vector = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            one_hot_row = []\n",
        "            for j in range(X.shape[1]):\n",
        "\n",
        "                category_index = self.categories[j].index(X[i, j])\n",
        "                category_one_hot =[0] *len(self.categories[j])\n",
        "                category_one_hot[category_index] = 1\n",
        "\n",
        "                one_hot_row.extend(category_one_hot)\n",
        "            one_hot_vector.append(one_hot_row)\n",
        "        return np.array(one_hot_vector)"
      ],
      "metadata": {
        "id": "YTDGKrnOgGwK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'fashion_mnist'\n",
        "if dataset == 'fashion_mnist':\n",
        "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "elif dataset == 'mnist':\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "else:\n",
        "    raise ValueError('Invalid dataset name')\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels, test_size=0.1, random_state=42)\n",
        "train_input = []\n",
        "for i in range(len(X_train)):\n",
        "    train_input.append(list(np.concatenate(X_train[i]).flat))\n",
        "\n",
        "val_input = []\n",
        "for i in range(len(X_val)):\n",
        "    val_input.append(list(np.concatenate(X_val[i]).flat))\n",
        "\n",
        "test_input = []\n",
        "for i in range(len(test_images)):\n",
        "    test_input.append(list(np.concatenate(test_images[i]).flat))\n",
        "Y_train = np.array(Y_train)\n",
        "Y_val = np.array(Y_val)\n",
        "Y_test = np.array(test_labels)\n",
        "\n",
        "X_train = np.array(train_input) / 255.0\n",
        "X_test = np.array(test_input) / 255.0\n",
        "X_val = np.array(val_input) / 255.0\n",
        "\n",
        "enc = OneHotEncoder_from_scratch()\n",
        "enc.fit(Y_train.reshape(-1, 1))\n",
        "Y_train = enc.transform(Y_train.reshape(-1, 1))\n",
        "Y_val = enc.transform(Y_val.reshape(-1, 1))\n",
        "Y_test = enc.transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzdukjGZgZeJ",
        "outputId": "50ac94b2-8df5-4790-d8fc-950794475823"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(54000, 10) (6000, 10) (10000, 10)\n",
            "(54000, 784) (6000, 784) (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class of FeedForward Neural Network"
      ],
      "metadata": {
        "id": "DXX2kyFig0i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFNN:\n",
        "  def __init__(self, X, Y,\n",
        "               epochs = 100, \n",
        "               hidden_layer_count = 4,\n",
        "               hidden_layers =  [32, 64, 128, 256],\n",
        "               learning_rate = 0.001,\n",
        "               batch_size = 32,\n",
        "               activation='tanh',\n",
        "               weight_init='random',\n",
        "               loss = 'MSE',\n",
        "               weight_decay = 0):\n",
        "    \n",
        "    self.inputs =X.shape[1] # Number of inputs\n",
        "    self.outputs= Y.shape[1] # Number of outputs\n",
        "    self.epochs = epochs\n",
        "    self.hidden_layers = hidden_layer_count  # Number of hidden layers \n",
        "    self.network_size= [self.inputs] + hidden_layers +[self.outputs] # input layer + hidden layers + output layers\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.weights={} # It will create dictionary for weights and biases\n",
        "    self.weights_h = []\n",
        "    self.num_classes = Y.shape[1]\n",
        "    self.weight_init = weight_init\n",
        "    self.activation_function = activation\n",
        "    self.loss_function = loss\n",
        "    self.lambd = 0\n",
        "    np.random.seed(0)  # We will set seed value so that it will generate same random numebers every time\n",
        "\n",
        "    self.grad_derivatice={}\n",
        "    self.update_weights={}\n",
        "    self.prev_update_weights={}\n",
        "    for i in range(1,self.hidden_layers+1):\n",
        "      vw_key, vb_key, mb_key, mw_key = [f\"{key}{i}\" for key in ['vw', 'vb', 'mb', 'mw']]\n",
        "      self.update_weights[vw_key]=0\n",
        "      self.update_weights[vb_key]=0\n",
        "      self.update_weights[mb_key]=0\n",
        "      self.update_weights[mw_key]=0\n",
        "      self.prev_update_weights[vw_key]=0\n",
        "      self.prev_update_weights[vb_key]=0\n",
        "\n",
        "    \n",
        "    if self.weight_init == 'random':\n",
        "      for i in range(1, self.hidden_layers + 2):\n",
        "          weight_shape = (self.network_size[i - 1], self.network_size[i])\n",
        "          weight_scale = 0.1\n",
        "          self.weights[f'W{i}'] = np.random.normal(scale=weight_scale, size=weight_shape)*0.1\n",
        "          \n",
        "          bias_shape = (1, self.network_size[i])\n",
        "          self.weights[f'B{i}'] = np.zeros(bias_shape)\n",
        "\n",
        "    if self.weight_init == 'Xavier':\n",
        "      for i in range(1, self.hidden_layers + 2):\n",
        "          weight_shape = (self.network_size[i - 1], self.network_size[i])\n",
        "          weight_scale = 0.1\n",
        "          self.weights[f'W{i}'] = np.random.normal(scale=weight_scale, size=weight_shape)*np.sqrt(1/self.network_size[i-1])\n",
        "          \n",
        "          bias_shape = (1, self.network_size[i])\n",
        "          self.weights[f'B{i}'] = np.zeros(bias_shape)\n",
        "\n",
        "  def forward_activation(self, X):\n",
        "      activation_functions = {\n",
        "          'sigmoid': lambda x: 1.0 / (1.0 + np.exp(-x)),\n",
        "          'tanh': np.tanh,\n",
        "          'Relu': lambda x: np.maximum(0, x)\n",
        "      }\n",
        "      activation_function = activation_functions.get(self.activation_function)\n",
        "      if activation_function:\n",
        "          return activation_function(X)\n",
        "      else:\n",
        "          raise ValueError(f\"Unknown activation function '{self.activation_function}'\")\n",
        "\n",
        "\n",
        "  def grad_activation(self, X):\n",
        "      activation_gradients = {\n",
        "          'sigmoid': lambda x: x * (1 - x),\n",
        "          'tanh': lambda x: 1 - np.square(x),\n",
        "          'Relu': lambda x: 1.0 * (x > 0)\n",
        "      }\n",
        "      gradient_function = activation_gradients.get(self.activation_function)\n",
        "      if gradient_function:\n",
        "          return gradient_function(X)\n",
        "      else:\n",
        "          raise ValueError(f\"Unknown activation function '{self.activation_function}'\")\n",
        "\n",
        "\n",
        "  def softmax(self, X):\n",
        "    exps =np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "    return  exps /np.sum(exps, axis=1, keepdims=True)\n",
        "  \n",
        "\n",
        "  def forward_pass(self, X, weights=None):\n",
        "      if weights is None:\n",
        "          weights = self.weights\n",
        "      self.A = {}\n",
        "      self.H = {}\n",
        "      self.H[0] = X\n",
        "      for i in range(self.hidden_layers):\n",
        "          self.A[i+1] = self.H[i] @ weights[f'W{i+1}'] + weights[f'B{i+1}']\n",
        "          self.H[i+1] = self.forward_activation(self.A[i+1])\n",
        "      self.A[self.hidden_layers+1] = self.H[self.hidden_layers] @ weights[f'W{self.hidden_layers+1}'] + weights[f'B{self.hidden_layers+1}']\n",
        "      self.H[self.hidden_layers+1] = self.softmax(self.A[self.hidden_layers+1])\n",
        "      return self.H[self.hidden_layers+1]\n",
        "\n",
        "  def backprop(self, X, Y, weights=None):\n",
        "    if weights is None:\n",
        "        weights = self.weights\n",
        "\n",
        "    self.forward_pass(X, weights)\n",
        "    self.grad_derivatice = {}\n",
        "    L = self.hidden_layers + 1\n",
        "\n",
        "    if self.loss_function == 'CE':\n",
        "        self.grad_derivatice[f'dA{L}'] = (self.H[L] - Y) * (1/X.shape[0])\n",
        "    elif self.loss_function == 'MSE':\n",
        "        self.grad_derivatice[f'dA{L}'] = (1/X.shape[0]) * 2 * (self.H[L] - Y)\n",
        "\n",
        "    for k in range(L, 0, -1):\n",
        "        w_key, b_key, dw_key, db_key, da_key = [f\"{key}{k}\" for key in ['W', 'B', 'dW', 'dB', 'dA']]\n",
        "        self.grad_derivatice[dw_key] = np.matmul(self.H[k-1].T, self.grad_derivatice[da_key]) + self.lambd * weights[w_key]\n",
        "        self.grad_derivatice[db_key] = np.sum(self.grad_derivatice[da_key], axis=0).reshape(1, -1)\n",
        "        self.grad_derivatice[f'dH{k-1}'] = np.matmul(self.grad_derivatice[da_key], weights[w_key].T)\n",
        "        self.grad_derivatice[f'dA{k-1}'] = np.multiply(self.grad_derivatice[f'dH{k-1}'], self.grad_activation(self.H[k-1]))\n",
        "\n",
        "    return self.grad_derivatice[f'dH{k-1}']\n",
        "\n",
        "  def fit(self, X, Y, X_val, Y_val,algo= 'GD',a = 10, eps=1e-8, beta=0.9, beta1=0.9, beta2=0.9, gamma=0.9 ):\n",
        "    for num_epoch in tqdm(range(1, self.epochs+1), unit='epoch'):\n",
        "      m = X.shape[0]\n",
        "\n",
        "\n",
        "      if num_epoch % 5 == 0:\n",
        "        accuracy = self.accuracy_score(X, Y)\n",
        "        loss_train = self.Loss(X, Y)\n",
        "        loss_valid = self.Loss(X_val, Y_val)\n",
        "        val_accuracy = self.accuracy_score(X_val, Y_val)\n",
        "        library = {'epoch': num_epoch,           \n",
        "                'loss': loss_train,\n",
        "                'accuracy': accuracy,\n",
        "                'val_loss': loss_valid,\n",
        "                'val_accuracy': val_accuracy}\n",
        "\n",
        "        print('Epoch: {}, Train Loss: {}, Train Accuracy: {}, Val Loss: {}, Val Accuracy: {}'.format(library['epoch'], library['loss'], library['accuracy'], library['val_loss'], library['val_accuracy']))\n",
        "        if num_epoch == self.epochs:\n",
        "          print('Model trained successfully !')\n",
        "      \n",
        "      if algo == 'SGD':\n",
        "        for i in range(m):\n",
        "            rand_idx = np.random.randint(m)\n",
        "            x_i = X[rand_idx:rand_idx+1]\n",
        "            y_i = Y[rand_idx:rand_idx+1]\n",
        "            self.backprop(x_i, y_i)\n",
        "            for j in range(1, self.hidden_layers+1):\n",
        "              w_key, b_key, dw_key, db_key = [f\"{key}{j}\" for key in ['W', 'B', 'dW', 'dB']]\n",
        "              self.weights[w_key] -=self.learning_rate * self.grad_derivatice[dw_key]\n",
        "              self.weights[b_key] -=self.learning_rate * self.grad_derivatice[db_key]\n",
        "\n",
        "      elif algo == 'Momentum':\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            self.backprop(X_batch, Y_batch)\n",
        "\n",
        "            for i in range(1, self.hidden_layers+1):\n",
        "              w_key, b_key, vw_key, vb_key,dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "              self.update_weights[vw_key] = gamma *self.update_weights[vw_key] + self.learning_rate * (self.grad_derivatice[dw_key])\n",
        "              self.update_weights[vb_key] = gamma *self.update_weights[vb_key] + self.learning_rate * (self.grad_derivatice[db_key])\n",
        "              self.weights[w_key] -= self.update_weights[vw_key]\n",
        "              self.weights[b_key] -= self.update_weights[vb_key]\n",
        "\n",
        "      elif algo == 'RMSProp':\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            self.backprop(X_batch, Y_batch)\n",
        "\n",
        "            for i in range(1, self.hidden_layers+1):\n",
        "                w_key, b_key, vw_key, vb_key, dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                self.update_weights[vw_key] = beta * self.update_weights[vw_key] + (1 - beta) * ((self.grad_derivatice[dw_key])**2)\n",
        "                self.update_weights[vb_key] = beta * self.update_weights[vb_key] + (1 - beta) * ((self.grad_derivatice[db_key])**2)\n",
        "                self.weights[w_key] -= (self.learning_rate / (np.sqrt(self.update_weights[vw_key] + eps))) * (self.grad_derivatice[dw_key])\n",
        "                self.weights[b_key] -= (self.learning_rate / (np.sqrt(self.update_weights[vb_key] + eps))) * (self.grad_derivatice[db_key])\n",
        "\n",
        "      \n",
        "      elif algo == 'Adam':\n",
        "\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            self.backprop(X_batch, Y_batch)\n",
        "\n",
        "            for i in range(1, self.hidden_layers + 1):\n",
        "                w_key, b_key, vw_key, vb_key, mw_key, mb_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'mw', 'mb']]\n",
        "                dw_key, db_key= [f\"{key}{i}\" for key in ['dW', 'dB']]\n",
        "\n",
        "                self.update_weights[mw_key] = beta1 * self.update_weights[mw_key] + (1 - beta1) * self.grad_derivatice[dw_key]\n",
        "                self.update_weights[vw_key] = beta2 * self.update_weights[vw_key] + (1 - beta2) * (self.grad_derivatice[dw_key] ** 2)\n",
        "                mw_hat = self.update_weights[mw_key] / (1 - np.power(beta1, batch + 1))\n",
        "                vw_hat = self.update_weights[vw_key] / (1 - np.power(beta2, batch + 1))\n",
        "                self.weights[w_key] -= (self.learning_rate / np.sqrt(vw_hat + eps)) * mw_hat\n",
        "\n",
        "                self.update_weights[mb_key] = beta1 * self.update_weights[mb_key] + (1 - beta1) * self.grad_derivatice[db_key]\n",
        "                self.update_weights[vb_key] = beta2 * self.update_weights[vb_key] + (1 - beta2) * (self.grad_derivatice[db_key] ** 2)\n",
        "                mb_hat = self.update_weights[mb_key] / (1 - np.power(beta1, batch + 1))\n",
        "                vb_hat = self.update_weights[vb_key] / (1 - np.power(beta2, batch + 1))\n",
        "                self.weights[b_key] -= (self.learning_rate / np.sqrt(vb_hat + eps)) * mb_hat\n",
        "          \n",
        "      elif algo == 'NAG':\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        temp_weights = {}\n",
        "        for i in range(1, self.hidden_layers+2):\n",
        "          w_key, b_key = [f\"{key}{i}\" for key in ['W', 'B']]\n",
        "          temp_weights[w_key] = np.zeros_like(self.weights[w_key])\n",
        "          temp_weights[b_key] = np.zeros_like(self.weights[b_key])\n",
        "        \n",
        "        for batch in range(num_batches + 1):\n",
        "            start_index = batch *self.batch_size\n",
        "            end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "            X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "            for i in range(1,self.hidden_layers+1):\n",
        "                w_key, b_key, vw_key, vb_key,dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                self.update_weights[vw_key]=gamma*self.prev_update_weights[vw_key]\n",
        "                self.update_weights[vb_key]=gamma*self.prev_update_weights[vb_key]\n",
        "                temp_weights[w_key]=self.weights[w_key]-self.update_weights[vw_key]\n",
        "                temp_weights[b_key]=self.weights[b_key]-self.update_weights[vb_key]\n",
        "            self.backprop(X_batch,Y_batch,temp_weights)\n",
        "            for i in range(1,self.hidden_layers+1):\n",
        "                w_key, b_key, vw_key, vb_key,dw_key, db_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'dW', 'dB']]\n",
        "                self.update_weights[vw_key] = gamma *self.update_weights[vw_key] + self.learning_rate * (self.grad_derivatice[dw_key])\n",
        "                self.update_weights[vb_key] = gamma *self.update_weights[vb_key] + self.learning_rate * (self.grad_derivatice[db_key])\n",
        "                self.weights[w_key] -= self.learning_rate * (self.update_weights[vw_key])\n",
        "                self.weights[b_key] -= self.learning_rate * (self.update_weights[vb_key]) \n",
        "\n",
        "            self.prev_update_weights=self.update_weights\n",
        "\n",
        "\n",
        "\n",
        "      elif algo == 'Nadam':\n",
        "\n",
        "        num_examples = X.shape[0]\n",
        "        num_batches = num_examples //self.batch_size\n",
        "\n",
        "        num_updates = 0\n",
        "        for i in range(1, self.hidden_layers + 1):\n",
        "            w_key, b_key, vw_key, vb_key, mw_key, mb_key = [f\"{key}{i}\" for key in ['W', 'B', 'vw', 'vb', 'mw', 'mb']]\n",
        "            dw_key, db_key, mw_i_key, mb_i_key = [f\"{key}{i}\" for key in ['dW', 'dB', 'mw_inf', 'mb_inf']]\n",
        "\n",
        "            for batch in range(num_batches + 1):\n",
        "                start_index = batch *self.batch_size\n",
        "                end_index = min((batch+1)*self.batch_size, num_examples)\n",
        "                X_batch, Y_batch = X[start_index:end_index], Y[start_index:end_index]\n",
        "\n",
        "                self.backprop(X_batch, Y_batch)\n",
        "\n",
        "                num_updates += 1\n",
        "                self.update_weights.setdefault(mw_i_key, 0)\n",
        "                self.update_weights[mw_key] = beta1 * self.update_weights[mw_key] + (1 - beta1) * (self.grad_derivatice[dw_key] )\n",
        "                self.update_weights[vw_key] = beta2 * self.update_weights[vw_key] + (1 - beta2) * ((self.grad_derivatice[dw_key]) ** 2)\n",
        "                mw_hat = self.update_weights[mw_key] / (1 - np.power(beta1, num_updates))\n",
        "                vw_hat = self.update_weights[vw_key] / (1 - np.power(beta2, num_updates))\n",
        "                mw_inf = beta1 * self.update_weights[mw_i_key] + (1 - beta1) * np.abs(self.grad_derivatice[dw_key])\n",
        "                mw_inf_hat = mw_inf / (1 - np.power(beta1, num_updates))\n",
        "                self.weights[w_key] -= (self.learning_rate / np.sqrt(vw_hat + eps)) * ((beta1 * mw_hat) + ((1 - beta1) * self.grad_derivatice[dw_key])) / (1 - np.power(beta2, num_updates)) + self.learning_rate * eps * np.sqrt(1 - np.power(beta2, num_updates)) * mw_inf_hat\n",
        "\n",
        "                self.update_weights.setdefault(mb_i_key, 0)\n",
        "                self.update_weights[mb_key] = beta1 * self.update_weights[mb_key] + (1 - beta1) * (self.grad_derivatice[db_key])\n",
        "                self.update_weights[vb_key] = beta2 * self.update_weights[vb_key] + (1 - beta2) * ((self.grad_derivatice[db_key]) ** 2)\n",
        "                mb_hat = self.update_weights[mb_key] / (1 - np.power(beta1, num_updates))\n",
        "                vb_hat = self.update_weights[vb_key] / (1 - np.power(beta2, num_updates))\n",
        "                mb_inf = beta1 * self.update_weights[mb_i_key] + (1 - beta1) * np.abs(self.grad_derivatice[db_key])\n",
        "                mb_inf_hat = mb_inf / (1 - np.power(beta1, num_updates))\n",
        "                self.weights[b_key] -= (self.learning_rate / np.sqrt(vb_hat + eps)) * ((beta1 * mb_hat) + ((1 - beta1) * self.grad_derivatice[db_key])) / (1 - np.power(beta2, num_updates)) + self.learning_rate * eps * np.sqrt(1 - np.power(beta2, num_updates)) * mb_inf_hat\n",
        "       \n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = (self.forward_pass(X))\n",
        "    return np.array(Y_pred).squeeze()\n",
        "  \n",
        "  def accuracy_score(self, X, Y):\n",
        "    Y_true = np.argmax(Y, axis=1).reshape(-1, 1)\n",
        "    pred_labels = np.argmax(self.predict(X), axis=1).reshape(-1,1)\n",
        "    return np.sum(pred_labels == Y_true) / len(Y)\n",
        "\n",
        "  def Loss(self, X, Y):\n",
        "    Y_pred = self.predict(X)\n",
        "    if self.loss_function== 'CE':\n",
        "        loss = -np.mean(Y * np.log(Y_pred + 1e-8))\n",
        "    elif self.loss_function == 'MSE':\n",
        "        loss = np.mean((Y - Y_pred)**2)\n",
        "    return loss\n",
        "\n",
        "  def performance(self, X_test, Y_test):\n",
        "    loss = self.Loss(X_test, Y_test)\n",
        "    accuracy = self.accuracy_score(X_test, Y_test)\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "  def confusion_matrix(self, X, Y):\n",
        "\n",
        "      actual_labels = np.argmax(Y, axis=1)\n",
        "      predicted_labels = np.argmax(self.forward_pass(X), axis=1)\n",
        "\n",
        "\n",
        "      available_classes = np.unique(np.concatenate((actual_labels, predicted_labels)))\n",
        "\n",
        "      confusion_matrix_ = np.zeros((len(available_classes), len(available_classes)), dtype=int)\n",
        "      for i, actual in enumerate(available_classes):\n",
        "          for j, predicted in enumerate(available_classes):\n",
        "              confusion_matrix_[i,j] = np.where((actual_labels == actual) & (predicted_labels == predicted))[0].shape[0]\n",
        "\n",
        "\n",
        "\n",
        "      return confusion_matrix_\n",
        "\n",
        "\n",
        "\n",
        "  def confusion_matrix_plot(self, confusion_matrix, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
        "    confusion_matrix = confusion_matrix/10\n",
        "    plt.matshow(confusion_matrix, cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(confusion_matrix))\n",
        "    plt.xticks(tick_marks)\n",
        "    plt.yticks(tick_marks)\n",
        "    plt.ylabel('actual')\n",
        "    plt.xlabel('predicted')\n",
        "\n",
        "\n",
        "  def wandlog(self, num_epoch, X, Y,X_val, Y_val):\n",
        "    accuracy = self.accuracy_score(X, Y)\n",
        "    loss_train = self.Loss(X, Y)\n",
        "    loss_valid = self.Loss(X_val, Y_val)\n",
        "    val_accuracy = self.accuracy_score(X_val, Y_val)\n",
        "    \n",
        "    if num_epoch % 5== 0:\n",
        "      accuracy = self.accuracy_score(X, Y)\n",
        "      loss_train = self.Loss(X, Y)\n",
        "      loss_valid = self.Loss(X_val, Y_val)\n",
        "      val_accuracy = self.accuracy_score(X_val, Y_val)\n",
        "      library = {'epoch': num_epoch,           \n",
        "              'loss': loss_train,\n",
        "              'accuracy': accuracy,\n",
        "              'val_loss': loss_valid,\n",
        "              'val_accuracy': val_accuracy}\n",
        "\n",
        "      print('Epoch: {}, Train Loss: {}, Train Accuracy: {}, Val Loss: {}, Val Accuracy: {}'.format(library['epoch'], library['loss'], library['accuracy'], library['val_loss'], library['val_accuracy']))\n",
        "      if num_epoch == self.epochs:\n",
        "        print('Model trained successfully !')\n",
        "    \n",
        "  \n",
        "# import itertools\n",
        "# #X_train, X_val, X_test, Y_train, Y_val, Y_test = X_train[0:10, :], X_val[0:10, :], X_test[0:10, :], Y_train[0:10, :], Y_val[0:10, :], Y_test[0:10, :]\n",
        "\n",
        "# algos = ['SGD','Momentum', 'NAG',  'RMSProp', 'Adam', 'Nadam']\n",
        "# init_method = ['random', 'Xavier']\n",
        "# loss = ['CE', 'MSE']\n",
        "# activation = ['sigmoid', 'tanh', 'Relu']\n",
        "# c = 0\n",
        "# for algo, init, loss_fn, act in itertools.product(algos, init_method, loss, activation):\n",
        "#   print(algo, init, loss_fn, act)\n",
        "#   model = FFNN(X_train, Y_train,\n",
        "#                     epochs=1,\n",
        "#                     hidden_layer_count=1,\n",
        "#                     hidden_layers=[1],\n",
        "#                     learning_rate=0.001,\n",
        "#                     batch_size=128,\n",
        "#                     activation=act,\n",
        "#                     weight_init=init,\n",
        "#                     loss=loss_fn)\n",
        "#   model.fit(X_train, Y_train, X_val, Y_val, algo=algo)\n",
        "#   confusion_matrix = model.confusion_matrix(X_test, Y_test)\n",
        "#   print(confusion_matrix.shape)\n",
        "#   print(model.accuracy_score(X_test, Y_test))\n",
        "#   #model.confusion_matrix_plot(confusion_matrix)\n",
        "#   c = c + 1\n",
        "# print(c)\n",
        "\n",
        "  \n",
        "model = FFNN(X_train, Y_train,\n",
        "                  epochs = 20, \n",
        "                  hidden_layer_count = 3,\n",
        "                  hidden_layers =  [512, 512, 512],\n",
        "                  learning_rate = 0.001,\n",
        "                  batch_size = 32,\n",
        "                  activation='Relu',\n",
        "                  weight_init='random',\n",
        "                  loss = 'CE',\n",
        "                  weight_decay = 0)\n",
        "model.fit(X_train, Y_train, X_val, Y_val,algo= 'Nadam', a = 1)\n",
        "confusion_matrix = model.confusion_matrix(X_test, Y_test)\n",
        "print(confusion_matrix)\n",
        "model.confusion_matrix_plot(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552,
          "referenced_widgets": [
            "d33d21840c9343a0b8ddebbe9b61992e",
            "6d656b89b97a438085b935037c4e7887",
            "5b0759f7e9924a7fa0bd1fc8e2c72249",
            "2ed0f08664bb42b794f4f47450200999",
            "7f4747de7e1243f296ea898eb42b6201",
            "11797701a5d74aa385229617d39a782f",
            "aaa358deeb6e43459573727d5a72f11b",
            "5027f501dd064314a0112b4cf6583cac",
            "94004f84ed504f579a22d6fbda858233",
            "b9b65386879c4860b1ee91a0f812ccbb",
            "3264396849d042ad943de221afda89c3"
          ]
        },
        "id": "roqXcqcDgrri",
        "outputId": "828a3b5a-30ed-487d-d0ad-2a9cf944a2d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?epoch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d33d21840c9343a0b8ddebbe9b61992e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Train Loss: 0.03921202110896331, Train Accuracy: 0.8639444444444444, Val Loss: 0.04202225220745869, Val Accuracy: 0.8575\n",
            "Epoch: 10, Train Loss: 0.028877141418426556, Train Accuracy: 0.8996851851851851, Val Loss: 0.03559918917593271, Val Accuracy: 0.8828333333333334\n",
            "Epoch: 15, Train Loss: 0.02745118628389362, Train Accuracy: 0.9044629629629629, Val Loss: 0.03953543723984375, Val Accuracy: 0.8753333333333333\n",
            "Epoch: 20, Train Loss: 0.024048761489478373, Train Accuracy: 0.917, Val Loss: 0.04030222852722182, Val Accuracy: 0.8805\n",
            "Model trained successfully !\n",
            "[[777   1   7  24   2   2 181   0   6   0]\n",
            " [ 11 952   2  27   5   0   2   0   1   0]\n",
            " [ 23   0 700  20 107   0 149   0   1   0]\n",
            " [ 20   2   5 902  31   0  37   0   3   0]\n",
            " [  0   0  63  47 779   0 108   0   3   0]\n",
            " [  0   0   0   1   0 962   0  18   0  19]\n",
            " [ 92   1  40  30  43   0 789   0   5   0]\n",
            " [  0   0   0   0   0  21   0 954   0  25]\n",
            " [  6   0   2   9   2   5   7   3 966   0]\n",
            " [  0   0   0   0   0  12   1  39   0 948]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}